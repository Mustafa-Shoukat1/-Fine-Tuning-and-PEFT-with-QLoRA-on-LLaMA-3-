{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"3bad8fb68620442397a0e577d546d84b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dff067093ef44880a7620fcf4c955fab","IPY_MODEL_2a49339d8b274a1dbabd552a26c54382","IPY_MODEL_3491826687564fdea81e529b925f94c8"],"layout":"IPY_MODEL_7124add7c0a34ca4ad80ba641696147e"}},"dff067093ef44880a7620fcf4c955fab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3628892f75b54aa380203ac6717cb11a","placeholder":"​","style":"IPY_MODEL_80ee301624e248868e52e5048ecdecd3","value":"config.json: 100%"}},"2a49339d8b274a1dbabd552a26c54382":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d29e966264e64e269ef2822081570698","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8be329b8ada34b49a597157f046b4e20","value":570}},"3491826687564fdea81e529b925f94c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42e71d16e48542619601e64654a86c28","placeholder":"​","style":"IPY_MODEL_e164781c4a2d4b89926da165d694f27b","value":" 570/570 [00:00&lt;00:00, 20.3kB/s]"}},"7124add7c0a34ca4ad80ba641696147e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3628892f75b54aa380203ac6717cb11a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80ee301624e248868e52e5048ecdecd3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d29e966264e64e269ef2822081570698":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8be329b8ada34b49a597157f046b4e20":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"42e71d16e48542619601e64654a86c28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e164781c4a2d4b89926da165d694f27b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2fbf210a594490382580d6d9238e01b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cffa7e53e5b84e90a7238750f31579db","IPY_MODEL_d4aec5c6f40f4c4c855a5b5473140a92","IPY_MODEL_5d8d70330ec94b1b9f71245bc498f9fc"],"layout":"IPY_MODEL_e4cf98193dcd4a3aa566cf41ddb9f0a8"}},"cffa7e53e5b84e90a7238750f31579db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b8c72741c144d3ca4850c3f776cd59e","placeholder":"​","style":"IPY_MODEL_facfe3f52b764b5e96f962f3617aae9c","value":"model.safetensors: 100%"}},"d4aec5c6f40f4c4c855a5b5473140a92":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6dde12dc74d349c0b7decb2d8bf34c9c","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_708e8e3323da4f35ad0678fb9084f28f","value":440449768}},"5d8d70330ec94b1b9f71245bc498f9fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa2ac77d4cc14619b04095e1550fdd1a","placeholder":"​","style":"IPY_MODEL_01d8592858fd4eb89414dd18c09ffeb4","value":" 440M/440M [00:02&lt;00:00, 181MB/s]"}},"e4cf98193dcd4a3aa566cf41ddb9f0a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b8c72741c144d3ca4850c3f776cd59e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"facfe3f52b764b5e96f962f3617aae9c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6dde12dc74d349c0b7decb2d8bf34c9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"708e8e3323da4f35ad0678fb9084f28f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa2ac77d4cc14619b04095e1550fdd1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01d8592858fd4eb89414dd18c09ffeb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24e2a78ffa8d413f8362ff903770bfed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5670c8d923aa4254bfc73b7dca8c8cc2","IPY_MODEL_b097fbf3bf3b4cb3965af6f51f186154","IPY_MODEL_55b871455d7545b185da54895d872b9e"],"layout":"IPY_MODEL_3ff76d84b555409492e8ba9886a4eafe"}},"5670c8d923aa4254bfc73b7dca8c8cc2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53d66e1354bd4ccea309023394c12919","placeholder":"​","style":"IPY_MODEL_ba2c814420e14e9aa79123a93557a65f","value":"Downloading builder script: "}},"b097fbf3bf3b4cb3965af6f51f186154":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fd67eaad22a4df5a597ed6d01ced270","max":1844,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd36a59eda674652a2ea227823642d3c","value":1844}},"55b871455d7545b185da54895d872b9e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_962a0ffb2a8d4c949b7c4c8aeb435e95","placeholder":"​","style":"IPY_MODEL_6ac191dc4d744a24966a1775a10c4be4","value":" 5.76k/? [00:00&lt;00:00, 298kB/s]"}},"3ff76d84b555409492e8ba9886a4eafe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53d66e1354bd4ccea309023394c12919":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba2c814420e14e9aa79123a93557a65f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fd67eaad22a4df5a597ed6d01ced270":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd36a59eda674652a2ea227823642d3c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"962a0ffb2a8d4c949b7c4c8aeb435e95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ac191dc4d744a24966a1775a10c4be4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2513f9047c5e48ebbbec77dfc2196ca5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_faeb6ddf5554433e87e2e890b4009ece","IPY_MODEL_22e539ecf3324e58a368839339534014","IPY_MODEL_c5176d02998447878fd7c323dfa23fc9"],"layout":"IPY_MODEL_d5d34b74bd41456ab2b476066acfa79c"}},"faeb6ddf5554433e87e2e890b4009ece":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df2fc5242d224bbe8d4ace9731b185c7","placeholder":"​","style":"IPY_MODEL_c171ac31e6394342b564bc371a835d14","value":"Map: 100%"}},"22e539ecf3324e58a368839339534014":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cd66a1b136f047b599a865d3eb0e440a","max":872,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0cc0ef4a7fc84d1ea24281b310e636d7","value":872}},"c5176d02998447878fd7c323dfa23fc9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0641c69b84bf4bdf988ec787823b94ed","placeholder":"​","style":"IPY_MODEL_6faffbe7db6b476483d3dd71da898a38","value":" 872/872 [00:00&lt;00:00, 3593.09 examples/s]"}},"d5d34b74bd41456ab2b476066acfa79c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df2fc5242d224bbe8d4ace9731b185c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c171ac31e6394342b564bc371a835d14":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cd66a1b136f047b599a865d3eb0e440a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cc0ef4a7fc84d1ea24281b310e636d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0641c69b84bf4bdf988ec787823b94ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6faffbe7db6b476483d3dd71da898a38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"position: relative; text-align: center; background-image: url('data:image/jpeg;base64,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'); background-size: 50%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n        <h1 style=\"color: red; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\">Welcome!</h1>\n        <p style=\"color: #1976D2; font-size: 18px; margin: 10px 0;\">\n            I'm Mustafa Shoukat, a data scientist. I'm in the world of LLMs and exploring various concepts and techniques to enhance my skills. In this notebook, I'll unlock the potential of your models with precision and efficiency.\n        </p>\n        <p style=\"color: #37983B; font-size: 16px; font-style: italic; margin: 10px 0;\">\n            \"Community empowers growth through shared knowledge and mutual support.\"\n        </p>\n        <p style=\"color: #2980B9; font-size: 16px; font-style: italic; margin: 10px 0;\">\n            <strong>About Notebook:</strong> 🧠 Fine-Tuning and PEFT with QLoRA on LLaMA 3\n        </p>\n        <p style=\"color: #27AE60; font-size: 16px; font-style: italic; margin: 10px 0;\">\n            This notebook delves into the advanced techniques of fine-tuning and Parameter-Efficient Fine-Tuning (PEFT) using QLoRA on the LLaMA 3 model. Designed for data science enthusiasts and professionals, it offers hands-on experience and practical insights to enhance model performance with efficient use of computational resources. Join the journey to master these cutting-edge techniques and elevate your machine learning projects.\n        </p>\n        <h2 style=\"color: red; margin-top: 15px; font-size: 28px;\">Contact Information</h2>\n        <table style=\"width: 100%; margin-top: 15px; border-collapse: collapse;\">\n            <tr style=\"background-color: #64B5F6; color: #ffffff;\">\n                <th style=\"padding: 8px; border-bottom: 2px solid #1976D2;\">Name</th>\n                <th style=\"padding: 8px; border-bottom: 2px solid #1976D2;\">Email</th>\n                <th style=\"padding: 8px; border-bottom: 2px solid #1976D2;\">LinkedIn</th>\n                <th style=\"padding: 8px; border-bottom: 2px solid #1976D2;\">GitHub</th>\n                <th style=\"padding: 8px; border-bottom: 2px solid #1976D2;\">Kaggle</th>\n            </tr>\n            <tr style=\"background-color: #FFFFFF; color: #000000;\">\n                <td style=\"padding: 8px;\">Mustafa Shoukat</td>\n                <td style=\"padding: 8px;\">mustafashoukat.ai@gmail.com</td>\n                <td style=\"padding: 8px;\">\n                    <a href=\"https://www.linkedin.com/in/mustafashoukat/\" target=\"_blank\">\n                        <img src=\"https://img.shields.io/badge/LinkedIn-0e76a8.svg?style=for-the-badge&logo=LinkedIn&logoColor=white\" alt=\"LinkedIn Badge\" style=\"border-radius: 5px; width: 100px;\">\n                    </a>\n                </td>\n                <td style=\"padding: 8px;\">\n                    <a href=\"https://github.com/Mustafa-Shoukat1\" target=\"_blank\">\n                        <img src=\"https://img.shields.io/badge/GitHub-171515.svg?style=for-the-badge&logo=GitHub&logoColor=white\" alt=\"GitHub Badge\" style=\"border-radius: 5px; width: 100px;\">\n                    </a>\n                </td>\n                <td style=\"padding: 8px;\">\n                    <a href=\"https://www.kaggle.com/mustafashoukat\" target=\"_blank\">\n                        <img src=\"https://img.shields.io/badge/Kaggle-20beff.svg?style=for-the-badge&logo=Kaggle&logoColor=white\" alt=\"Kaggle Badge\" style=\"border-radius: 5px; width: 100px;\">\n                    </a>\n                </td>\n            </tr>\n        </table>\n    </div>\n</div>\n\n\n<div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n    <h1 style=\"color: red; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px; text-align: center;\"></h1>\n    <p style=\"color: #1976D2; font-size: 18px; margin: 10px 0; text-align: center;\">\n        <img src=\"https://miro.medium.com/v2/resize:fit:1200/1*rOW5plKBuMlGgpD0SO8nZA.png\" alt=\"ORPO Diagram\" style=\"display: block; margin: 0 auto; max-width: 100%; height: auto;\"/>\n    </p>\n</div>\n\n<div style=\"position: relative; text-align: center; background-image: url('https://th.bing.com/th/id/OIP.zzdnmTrMMKuSlTl7PPSZWwHaE8?rs=1&pid=ImgDetMain'); background-size: 70%; background-position: center; border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <div style=\"position: relative; z-index: 1; background-color: rgba(255, 255, 255, 0.9); backdrop-filter: blur(10px); border-radius: 20px; padding: 20px;\">\n        <h1 style=\"color: red; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\">Traditional vs New Transfer learning</h1>\n        <p style=\"color: #1976D2; font-size: 18px; margin: 10px 0;\">\n\n### Traditional Transfer Learning\n- **Uses:** A pre-trained model (weights and architecture) trained on a large dataset (source task) for a new task (target task).\n- **Key Point:** Freezes most of the pre-trained model's parameters, only training a small subset (usually the final layers) on the new data.\n- **Benefit:** Faster training, leverages learned features, good for tasks with limited data.\n\n### Fine-Tuning\n- **Also leverages:** A pre-trained model for a new task.\n- **Key Point:** Trains all the parameters of the pre-trained model on the new data.\n- **Benefit:** Allows for more significant adaptation to the new task, potentially higher performance compared to transfer learning.\n- **Drawback:** Can be computationally expensive, potentially prone to overfitting with small datasets.\n\n### Parameter-Efficient Fine-Tuning (PEFT)\n- **A specific strategy:** Within fine-tuning.\n- **Key Point:** Focuses on training only a subset of the pre-trained model's parameters, often identified through techniques like saliency maps or gradient analysis.\n- **Benefit:** Reduces computational cost compared to full fine-tuning while achieving comparable performance in some cases.\n\n\n### Adapter\nAdapters are a special type of submodule that can be added to pre-trained language models to modify their hidden representation during fine-tuning. By inserting adapters after the multi-head attention and feed-forward layers in the transformer architecture, we can update only the parameters in the adapters during fine-tuning while keeping the rest of the model parameters frozen.\n\nAdopting adapters can be a straightforward process. All that is required is to add adapters into each transformer layer and place a classifier layer on top of the pre-trained model. By updating the parameters of the adapters and the classifier head, we can improve the performance of the pre-trained model on a particular task without updating the entire model. This approach can save time and computational resources while still producing impressive results.\n\n### LoRA\nLow-rank adaptation (LoRA) of large language models is another approach in the area of fine-tuning models for specific tasks or domains. Similar to the adapters, LoRA is also a small trainable submodule that can be inserted into the transformer architecture. It involves freezing the pre-trained model weights and injecting trainable rank decomposition matrices into each layer of the transformer architecture, greatly diminishing the number of trainable parameters for downstream tasks. This method can minimize the number of trainable parameters by up to 10,000 times and the GPU memory necessity by 3 times while still performing on par or better than fine-tuning model quality on various tasks. LoRA also allows for more efficient task-switching, lowering the hardware barrier to entry, and has no additional inference latency compared to other methods.\n\n### Fine-tune Llama 3 with ORPO\nORPO is a new exciting fine-tuning technique that combines the traditional supervised fine-tuning and preference alignment stages into a single process. This reduces the computational resources and time required for training. Moreover, empirical results demonstrate that ORPO outperforms other alignment methods on various model sizes and benchmarks.\n\nThere are now many methods to align large language models (LLMs) with human preferences. Reinforcement learning with human feedback (RLHF) was one of the first and brought us ChatGPT, but RLHF is very costly. DPO (Differentiable Preference Optimization), IPO (Interactive Preference Optimization), and KTO (Knowledge Transfer Optimization) are notably cheaper than RLHF as they don’t need a reward model.\n\nWhile DPO and IPO are cheaper, they still require to train two different models. One model for the supervised fine-tuning (SFT) step, i.e., training the model to answer instructions, and then the model to align with human preferences using the SFT model for initialization and as a reference.\n\n### ORPO\nInstruction tuning and preference alignment are essential techniques for adapting Large Language Models (LLMs) to specific tasks. Traditionally, this involves a multi-stage process: 1/ Supervised Fine-Tuning (SFT) on instructions to adapt the model to the target domain, followed by 2/ preference alignment methods like Reinforcement Learning with Human Feedback (RLHF) or Direct Preference Optimization (DPO) to increase the likelihood of generating preferred responses over rejected ones.\n\n\nORPO is yet another new method for LLM alignment but this one doesn’t even need the SFT model. With ORPO, the LLM jointly learns to answer instructions and human preferences.\nORPO: Monolithic Preference Optimization without Reference Model\n        </p>\n    </div>\n</div>","metadata":{}},{"cell_type":"code","source":"!pip install transformers==4.30.2\n!pip install datasets\n\nfrom datasets import load_dataset\nimport numpy as np\nraw_dataset=load_dataset('glue','sst2')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nJd5n4exdK9","outputId":"e3f9ac86-b3d2-44a0-8e3e-6299df377dbe","execution":{"iopub.status.busy":"2024-06-28T17:29:51.096714Z","iopub.execute_input":"2024-06-28T17:29:51.097007Z","iopub.status.idle":"2024-06-28T17:30:36.743394Z","shell.execute_reply.started":"2024-06-28T17:29:51.096982Z","shell.execute_reply":"2024-06-28T17:30:36.742543Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting transformers==4.30.2\n  Downloading transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (0.23.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (2.32.3)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.2)\n  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.30.2) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (2024.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.30.2) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.30.2) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.30.2) (2024.2.2)\nDownloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, transformers\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.19.1\n    Uninstalling tokenizers-0.19.1:\n      Successfully uninstalled tokenizers-0.19.1\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.41.2\n    Uninstalling transformers-4.41.2:\n      Successfully uninstalled transformers-4.41.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkaggle-environments 1.14.11 requires transformers>=4.33.1, but you have transformers 4.30.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.30.2\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/35.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eafe2ae5f016495c93eccf5ec96a1a59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/3.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52acee662b1847f8a865a6a8bb706306"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/72.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e93262233bc42a58a7f42961e2ada54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/148k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0b3d18cb2224d2885dbe62538d67661"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/67349 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38f4eb4e403c49b89dc75385e27485e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75c2ba98cf0641a4b9355a81d6f8e2c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"498cbc0bf8fa4ec3b025845184f7ae08"}},"metadata":{}}]},{"cell_type":"markdown","source":"**'glue':**<br><br>\n\n- This is the name of the dataset group. GLUE (General Language Understanding Evaluation) is a benchmark for evaluating the performance of models across various NLP tasks.<br><br>\n\n\n\n**'sst2':**\n\n- This is the name of a specific dataset within the GLUE benchmark. The SST-2 dataset (Stanford Sentiment Treebank) is a collection of movie reviews from Rotten Tomatoes, labeled with sentiment (positive or negative).<br><br>\n\n\nSo, when we call load_dataset('glue', 'sst2'), it fetches the SST-2 dataset from the GLUE benchmark. This dataset can then be used for tasks such as sentiment analysis or fine-tuning pre-trained language models","metadata":{"id":"zDmZYUdSj-AD"}},{"cell_type":"code","source":"raw_dataset","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V-roQ_W5kWgn","outputId":"d1c0f136-0517-475a-b372-16ff2f16e6d3","execution":{"iopub.status.busy":"2024-06-28T17:30:36.745092Z","iopub.execute_input":"2024-06-28T17:30:36.745505Z","iopub.status.idle":"2024-06-28T17:30:36.752106Z","shell.execute_reply.started":"2024-06-28T17:30:36.745479Z","shell.execute_reply":"2024-06-28T17:30:36.751264Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 67349\n    })\n    validation: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 872\n    })\n    test: Dataset({\n        features: ['sentence', 'label', 'idx'],\n        num_rows: 1821\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"raw_dataset['train']","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-FbKGRRkZ-H","outputId":"a7f666a3-e57d-4636-98a4-6bd93eee788d","execution":{"iopub.status.busy":"2024-06-28T17:30:36.753249Z","iopub.execute_input":"2024-06-28T17:30:36.753523Z","iopub.status.idle":"2024-06-28T17:30:36.768471Z","shell.execute_reply.started":"2024-06-28T17:30:36.753499Z","shell.execute_reply":"2024-06-28T17:30:36.767501Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['sentence', 'label', 'idx'],\n    num_rows: 67349\n})"},"metadata":{}}]},{"cell_type":"code","source":"dir(raw_dataset['train'])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zGN5myI5khnN","outputId":"6a7d884d-e184-4524-c546-a903308e1865","execution":{"iopub.status.busy":"2024-06-28T17:30:36.771011Z","iopub.execute_input":"2024-06-28T17:30:36.771857Z","iopub.status.idle":"2024-06-28T17:30:36.782163Z","shell.execute_reply.started":"2024-06-28T17:30:36.771819Z","shell.execute_reply":"2024-06-28T17:30:36.781237Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"['_TF_DATASET_REFS',\n '__class__',\n '__del__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__enter__',\n '__eq__',\n '__exit__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__getitems__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__iter__',\n '__le__',\n '__len__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_build_local_temp_path',\n '_check_index_is_initialized',\n '_data',\n '_estimate_nbytes',\n '_fingerprint',\n '_format_columns',\n '_format_kwargs',\n '_format_type',\n '_generate_tables_from_cache_file',\n '_generate_tables_from_shards',\n '_get_cache_file_path',\n '_get_output_signature',\n '_getitem',\n '_indexes',\n '_indices',\n '_info',\n '_map_single',\n '_new_dataset_with_indices',\n '_output_all_columns',\n '_push_parquet_shards_to_hub',\n '_save_to_disk_single',\n '_select_contiguous',\n '_select_with_indices_mapping',\n '_split',\n 'add_column',\n 'add_elasticsearch_index',\n 'add_faiss_index',\n 'add_faiss_index_from_external_arrays',\n 'add_item',\n 'align_labels_with_mapping',\n 'builder_name',\n 'cache_files',\n 'cast',\n 'cast_column',\n 'citation',\n 'class_encode_column',\n 'cleanup_cache_files',\n 'column_names',\n 'config_name',\n 'data',\n 'dataset_size',\n 'description',\n 'download_checksums',\n 'download_size',\n 'drop_index',\n 'export',\n 'features',\n 'filter',\n 'flatten',\n 'flatten_indices',\n 'format',\n 'formatted_as',\n 'from_buffer',\n 'from_csv',\n 'from_dict',\n 'from_file',\n 'from_generator',\n 'from_json',\n 'from_list',\n 'from_pandas',\n 'from_parquet',\n 'from_polars',\n 'from_spark',\n 'from_sql',\n 'from_text',\n 'get_index',\n 'get_nearest_examples',\n 'get_nearest_examples_batch',\n 'homepage',\n 'info',\n 'is_index_initialized',\n 'iter',\n 'license',\n 'list_indexes',\n 'load_elasticsearch_index',\n 'load_faiss_index',\n 'load_from_disk',\n 'map',\n 'num_columns',\n 'num_rows',\n 'prepare_for_task',\n 'push_to_hub',\n 'remove_columns',\n 'rename_column',\n 'rename_columns',\n 'reset_format',\n 'save_faiss_index',\n 'save_to_disk',\n 'search',\n 'search_batch',\n 'select',\n 'select_columns',\n 'set_format',\n 'set_transform',\n 'shape',\n 'shard',\n 'shuffle',\n 'size_in_bytes',\n 'skip',\n 'sort',\n 'split',\n 'supervised_keys',\n 'take',\n 'task_templates',\n 'to_csv',\n 'to_dict',\n 'to_iterable_dataset',\n 'to_json',\n 'to_list',\n 'to_pandas',\n 'to_parquet',\n 'to_polars',\n 'to_sql',\n 'to_tf_dataset',\n 'train_test_split',\n 'unique',\n 'version',\n 'with_format',\n 'with_transform']"},"metadata":{}}]},{"cell_type":"markdown","source":"- Calling dir(raw_dataset['train']) will return a list of attributes and methods available for the object corresponding to the training subset of the dataset loaded from the SST-2 dataset.","metadata":{"id":"sMj_OUBDksEA"}},{"cell_type":"code","source":"type(raw_dataset['train'])","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"aXSa6N2PkjVA","outputId":"32899bf9-83df-434c-86e2-cd36b291ee2e","execution":{"iopub.status.busy":"2024-06-28T17:30:36.783197Z","iopub.execute_input":"2024-06-28T17:30:36.783453Z","iopub.status.idle":"2024-06-28T17:30:36.793118Z","shell.execute_reply.started":"2024-06-28T17:30:36.783431Z","shell.execute_reply":"2024-06-28T17:30:36.792204Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"datasets.arrow_dataset.Dataset"},"metadata":{}}]},{"cell_type":"markdown","source":"- raw_dataset['train'] object belongs to the datasets library's arrow_dataset module, specifically the Dataset class within it.","metadata":{"id":"qDZPjeI3k__n"}},{"cell_type":"code","source":"raw_dataset['train'].data","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hg8-5XWikmov","outputId":"dc253004-e376-46c5-d663-8ea7e7e19927","execution":{"iopub.status.busy":"2024-06-28T17:30:36.794280Z","iopub.execute_input":"2024-06-28T17:30:36.794597Z","iopub.status.idle":"2024-06-28T17:30:36.802279Z","shell.execute_reply.started":"2024-06-28T17:30:36.794568Z","shell.execute_reply":"2024-06-28T17:30:36.801406Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"MemoryMappedTable\nsentence: string\nlabel: int64\nidx: int32\n----\nsentence: [[\"hide new secretions from the parental units \",\"contains no wit , only labored gags \",\"that loves its characters and communicates something rather beautiful about human nature \",\"remains utterly satisfied to remain the same throughout \",\"on the worst revenge-of-the-nerds clichés the filmmakers could dredge up \",...,\"you wish you were at home watching that movie instead of in the theater watching this one \",\"'s no point in extracting the bare bones of byatt 's plot for purposes of bland hollywood romance \",\"underdeveloped \",\"the jokes are flat \",\"a heartening tale of small victories \"],[\"suspense , intriguing characters and bizarre bank robberies , \",\"a gritty police thriller with all the dysfunctional family dynamics one could wish for \",\"with a wonderful ensemble cast of characters that bring the routine day to day struggles of the working class to life \",\"nonetheless appreciates the art and reveals a music scene that transcends culture and race . \",\"do we really need the tiger beat version ? \",...,\"when there 's nothing else happening \",\"on cable \",\"it with ring , \",\"far from a groundbreaking endeavor \",\"that these women are spectacular \"],...,[\"it does turn out to be a bit of a cheat in the end \",\"may be convinced that he has something significant to say \",\"to be both hugely entertaining and uplifting . \",\", boredom never takes hold . \",\"left to work with , sort of like michael jackson 's nose \",...,\"from a severe case of hollywood-itis \",\"the very best of them \",\"thrills , \",\"'s attracting audiences to unfaithful \",\"impressively delicate range \"],[\"starts off promisingly but then proceeds to flop \",\"distinguished actor \",\"on their parents ' anguish \",\"pays off and is effective if you stick with it \",\"is n't particularly funny \",...,\"a delightful comedy \",\"anguish , anger and frustration \",\"at achieving the modest , crowd-pleasing goals it sets for itself \",\"a patient viewer \",\"this new jangle of noise , mayhem and stupidity must be a serious contender for the title . \"]]\nlabel: [[0,0,1,0,0,...,0,0,0,0,1],[1,1,1,1,0,...,0,0,1,0,1],...,[0,0,1,1,0,...,0,1,1,1,1],[0,1,0,1,0,...,1,0,1,1,0]]\nidx: [[0,1,2,3,4,...,995,996,997,998,999],[1000,1001,1002,1003,1004,...,1995,1996,1997,1998,1999],...,[66000,66001,66002,66003,66004,...,66995,66996,66997,66998,66999],[67000,67001,67002,67003,67004,...,67344,67345,67346,67347,67348]]"},"metadata":{}}]},{"cell_type":"code","source":"raw_dataset['train'][0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LI-5nNEukpNv","outputId":"513af11a-4183-4b5f-807e-6b65d8bc596b","execution":{"iopub.status.busy":"2024-06-28T17:30:36.803440Z","iopub.execute_input":"2024-06-28T17:30:36.803703Z","iopub.status.idle":"2024-06-28T17:30:36.814929Z","shell.execute_reply.started":"2024-06-28T17:30:36.803681Z","shell.execute_reply":"2024-06-28T17:30:36.813903Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'sentence': 'hide new secretions from the parental units ',\n 'label': 0,\n 'idx': 0}"},"metadata":{}}]},{"cell_type":"code","source":"raw_dataset['train'].features['label'].int2str(1)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"EY2ohoJimWdj","outputId":"0ac1190b-a193-4ab9-e1f6-89e183c21c52","execution":{"iopub.status.busy":"2024-06-28T17:30:36.815955Z","iopub.execute_input":"2024-06-28T17:30:36.816206Z","iopub.status.idle":"2024-06-28T17:30:36.826392Z","shell.execute_reply.started":"2024-06-28T17:30:36.816184Z","shell.execute_reply":"2024-06-28T17:30:36.825574Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"'positive'"},"metadata":{}}]},{"cell_type":"code","source":"raw_dataset['train'].features['label'].int2str(0)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"x5kZJhrlmdA_","outputId":"d96326ca-5d04-4c3c-ddc5-8af4ada5a906","execution":{"iopub.status.busy":"2024-06-28T17:30:36.827373Z","iopub.execute_input":"2024-06-28T17:30:36.827633Z","iopub.status.idle":"2024-06-28T17:30:36.837284Z","shell.execute_reply.started":"2024-06-28T17:30:36.827610Z","shell.execute_reply":"2024-06-28T17:30:36.836397Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'negative'"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer","metadata":{"id":"XxOarGErlMJU","execution":{"iopub.status.busy":"2024-06-28T17:30:36.841460Z","iopub.execute_input":"2024-06-28T17:30:36.841744Z","iopub.status.idle":"2024-06-28T17:30:38.554505Z","shell.execute_reply.started":"2024-06-28T17:30:36.841721Z","shell.execute_reply":"2024-06-28T17:30:38.553742Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model='distilbert-base-uncased'\ntokenizer=AutoTokenizer.from_pretrained(model)","metadata":{"id":"KmsH5UkrlS00","execution":{"iopub.status.busy":"2024-06-28T17:30:38.555557Z","iopub.execute_input":"2024-06-28T17:30:38.556053Z","iopub.status.idle":"2024-06-28T17:30:39.629043Z","shell.execute_reply.started":"2024-06-28T17:30:38.556026Z","shell.execute_reply":"2024-06-28T17:30:39.628327Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc414c4f757b473c8003ab7b50e36df4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd9311fab6b34ea1a3a37146b3a6c5d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b8fc20de5b341199110659e15e9cf5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06b890c39ca241e2a928e9826c75c025"}},"metadata":{}}]},{"cell_type":"markdown","source":"<div style=\"border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; background-color: black; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: yellow; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\"> 📚 DistilBERT Base Uncased and Its Parameters 🤖</h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"\n\n- The model distilbert-base-uncased refers to a version of the DistilBERT model, which is a distilled and smaller version of the original BERT model. Here's what you can infer about its capabilities:<br><br>\n\n**DistilBERT:**\n\n- DistilBERT is a transformer-based model developed by Hugging Face. It is trained to understand the context of words in a sentence and can be fine-tuned for various natural language processing (NLP) tasks.<br><br>\n\n\n\n\n- The term \"base\" typically refers to the size of the model. In this case, it suggests that distilbert-base-uncased is one of the base-sized variants of the DistilBERT model. Base-sized models are smaller and faster compared to larger variants like \"large\" or \"huge,\" but they might sacrifice some performance on certain tasks.<br><br>\n\n\n**Uncased:**\n\n- The \"uncased\" suffix indicates that the model is trained on lowercased text. This means that during both pre-training and fine-tuning, the model treats all text as lowercase. This simplifies the model's learning process, especially for languages like English where case may not always be semantically significant.","metadata":{"id":"VZdoD5pam9SY"}},{"cell_type":"code","source":"tokenized_sent=tokenizer(raw_dataset['train'][0:3]['sentence'])\nfrom pprint import pprint\nprint(tokenized_sent)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FMWOvE1hlnPy","outputId":"fe33ef01-ead8-4f2b-8404-df0ae1e0a3b1","execution":{"iopub.status.busy":"2024-06-28T17:30:39.630079Z","iopub.execute_input":"2024-06-28T17:30:39.630360Z","iopub.status.idle":"2024-06-28T17:30:39.636618Z","shell.execute_reply.started":"2024-06-28T17:30:39.630335Z","shell.execute_reply":"2024-06-28T17:30:39.635676Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"{'input_ids': [[101, 5342, 2047, 3595, 8496, 2013, 1996, 18643, 3197, 102], [101, 3397, 2053, 15966, 1010, 2069, 4450, 2098, 18201, 2015, 102], [101, 2008, 7459, 2049, 3494, 1998, 10639, 2015, 2242, 2738, 3376, 2055, 2529, 3267, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenized_fn(batch):\n  return tokenizer(batch['sentence'],truncation=True)","metadata":{"id":"K-W_WMVMl9pA","execution":{"iopub.status.busy":"2024-06-28T17:30:39.637698Z","iopub.execute_input":"2024-06-28T17:30:39.638027Z","iopub.status.idle":"2024-06-28T17:30:39.645656Z","shell.execute_reply.started":"2024-06-28T17:30:39.637997Z","shell.execute_reply":"2024-06-28T17:30:39.644980Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"- This function takes a batch of sentences, tokenizes them using the specified tokenizer, and returns the tokenized representations, potentially with truncation applied to ensure uniform sequence lengths within the batch.\n\n- BERT and DistilBERT models often have a maximum sequence length of 512 tokens.\n\n- When truncating sequences, it's common to choose a maximum length that balances computational resources with the need to preserve important information in the text. Choosing a length that is too short may result in loss of information, while choosing a length that is too long may lead to increased computational overhead.","metadata":{"id":"RvvxhdLloUNm"}},{"cell_type":"code","source":"tokenized_datasets=raw_dataset.map(tokenized_fn,batched=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["2513f9047c5e48ebbbec77dfc2196ca5","faeb6ddf5554433e87e2e890b4009ece","22e539ecf3324e58a368839339534014","c5176d02998447878fd7c323dfa23fc9","d5d34b74bd41456ab2b476066acfa79c","df2fc5242d224bbe8d4ace9731b185c7","c171ac31e6394342b564bc371a835d14","cd66a1b136f047b599a865d3eb0e440a","0cc0ef4a7fc84d1ea24281b310e636d7","0641c69b84bf4bdf988ec787823b94ed","6faffbe7db6b476483d3dd71da898a38"]},"id":"pSsv1w9kmWGO","outputId":"83299b4d-b0ab-44e9-c6b8-ceca4cb0d28e","execution":{"iopub.status.busy":"2024-06-28T17:30:39.646608Z","iopub.execute_input":"2024-06-28T17:30:39.646892Z","iopub.status.idle":"2024-06-28T17:30:42.412995Z","shell.execute_reply.started":"2024-06-28T17:30:39.646868Z","shell.execute_reply":"2024-06-28T17:30:42.412059Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/67349 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1dff73d03d0f4dc79270d04d70955997"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/872 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bd39b39b7e04aa7bc1073303ebef0c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1821 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f6e9d9362e64bf1a84e0d339826c0e4"}},"metadata":{}}]},{"cell_type":"code","source":"# from transformers import TrainingArguments\n\n# # Define training arguments\n# training_args = TrainingArguments(\n#     output_dir='./results',           # Output directory\n#     num_train_epochs=3,               # Number of training epochs\n#     per_device_train_batch_size=8,    # Batch size per device during training\n#     per_device_eval_batch_size=8,     # Batch size per device during evaluation\n#     logging_dir='./logs',             # Directory for storing logs\n#     logging_steps=100,                # Log every 100 steps\n#     save_steps=500,                   # Save checkpoint every 500 steps\n#     evaluation_strategy='epoch',      # Evaluate at the end of each epoch\n#     save_total_limit=2,               # Limit the total number of checkpoints\n#     load_best_model_at_end=True,      # Load the best model from checkpoint at the end of training\n#     metric_for_best_model='accuracy', # Metric to use for saving the best model\n#     greater_is_better=True            # Whether the 'metric_for_best_model' should be maximized\n# )\n\n\n\n# see  model check points in details","metadata":{"id":"V05b6I8Vqx63","execution":{"iopub.status.busy":"2024-06-28T17:30:42.414560Z","iopub.execute_input":"2024-06-28T17:30:42.414934Z","iopub.status.idle":"2024-06-28T17:30:42.420323Z","shell.execute_reply.started":"2024-06-28T17:30:42.414900Z","shell.execute_reply":"2024-06-28T17:30:42.419492Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**output_dir:**\n\n- This parameter specifies the directory where the model checkpoints and training results will be saved. For example, output_dir='./results' means that all output files will be stored in the results directory.<br><br>\n\n\n**Model Checkpoints:**\n\n- Model checkpoints are snapshots of a neural network model's state at certain points during training. These snapshots include the model's architecture as well as the values of its parameters (weights and biases). Checkpoints are typically saved periodically during training to disk, allowing the training process to be resumed from the point at which the checkpoint was saved.<br><br>\n\nCheckpoints serve several important purposes:\n\n**Resuming Training:** <br><br>\n\nIf training is interrupted (e.g., due to a system crash or manual termination), checkpoints allow training to be resumed from the most recent saved point, rather than starting from scratch.<br><br>\n\n**Evaluation and Inference:**\n\nCheckpoints can be loaded for evaluation on a validation or test set, or for making predictions on new data.<br><br>\n\n\n**Model Selection:**\n\nCheckpoints can be used to select the best-performing model based on evaluation metrics on a validation set.<br><br>\n\n\n**Training Results:**\n\nTraining results refer to various information and metrics collected during the training process. These results provide insights into the performance and behavior of the model as it learns from the training data. Common training results include:\n\n**Loss Values:**\n\nThe loss function measures how well the model's predictions match the true labels during training. Monitoring the loss values over time helps assess the model's learning progress.\n\n\n**Metrics:**\n\nMetrics such as accuracy, precision, recall, F1-score, etc., are often computed on a validation set during training to evaluate the model's performance. These metrics provide feedback on how well the model generalizes to unseen data.\n\n\n**Learning Curves:**\n\nLearning curves visualize the training and validation metrics (e.g., loss, accuracy) over epochs or training steps. They help diagnose issues such as overfitting or underfitting and assess the model's convergence.\n\n\n**Logs:**\n\nLogs contain additional information about the training process, such as training time, memory usage, and any warnings or errors encountered.","metadata":{"id":"-cHaoA-gq6Mf"}},{"cell_type":"markdown","source":"**num_train_epochs:**\n\nThis parameter determines the number of training epochs, indicating how many times the model will be trained on the entire training dataset. For example, num_train_epochs=3 means the model will be trained for 3 epochs.","metadata":{"id":"Bw6nwrmOsG8J"}},{"cell_type":"markdown","source":"**per_device_train_batch_size:**\n\nThis parameter sets the batch size per device (e.g., GPU or CPU) during training. For example, per_device_train_batch_size=8 means that 8 samples will be processed in parallel on each device during training.","metadata":{"id":"z2lI0KZAsMFM"}},{"cell_type":"markdown","source":"**per_device_eval_batch_size:**\n\nSimilar to per_device_train_batch_size, this parameter sets the batch size per device during evaluation. For example, per_device_eval_batch_size=8 means that 8 samples will be processed in parallel on each device during evaluation.","metadata":{"id":"zkr2u8fosUW4"}},{"cell_type":"markdown","source":"**logging_dir:**\n\nThis parameter specifies the directory where training logs will be stored. For example, logging_dir='./logs' means that logs will be saved in the logs directory.","metadata":{"id":"afp_1EqssaQ4"}},{"cell_type":"markdown","source":"**logging_steps:**\n\nThis parameter determines how often training metrics will be logged, specified as the number of training steps between each log entry. For example, logging_steps=100 means that training metrics will be logged every 100 steps.","metadata":{"id":"l8EqjY18sfOh"}},{"cell_type":"markdown","source":"**save_steps:**\n\nThis parameter sets the frequency of saving model checkpoints during training, specified as the number of training steps. For example, save_steps=500 means that a checkpoint will be saved every 500 steps.","metadata":{"id":"h1Qo4SSDsog6"}},{"cell_type":"markdown","source":"**evaluation_strategy:**\n\n\nThis parameter determines when evaluation is performed during training, either at the end of each epoch ('epoch') or at specified intervals of training steps ('steps'). For example, evaluation_strategy='epoch' means that evaluation will be performed at the end of each epoch.<br><br>\n\n\n- evaluation_strategy='epoch' specifies that the model should be evaluated at the end of each training epoch (num_train_epochs=3).<br><br>\n\n\n- After each epoch (full pass through the training dataset), the trainer will automatically evaluate the model on the evaluation dataset (eval_dataset) and compute evaluation metrics (e.g., accuracy, loss).<br><br>\n\n\n- This strategy is useful for monitoring the model's performance over training epochs and detecting any overfitting or underfitting trends.","metadata":{"id":"Nea4hzxdszmm"}},{"cell_type":"markdown","source":"**save_total_limit:**\n\nThis parameter sets a limit on the total number of checkpoints to keep. For example, save_total_limit=2 means that only the two most recent checkpoints will be saved, preventing excessive disk usage.","metadata":{"id":"eduODddms7oh"}},{"cell_type":"markdown","source":"**load_best_model_at_end:**\n\nThis parameter specifies whether the best model checkpoint based on the evaluation metric should be loaded at the end of training. For example, load_best_model_at_end=True means that the best model will be loaded.","metadata":{"id":"gHG5sVeBtEJQ"}},{"cell_type":"markdown","source":"**metric_for_best_model:**\n\nThis parameter determines the evaluation metric used for selecting the best model checkpoint. For example, metric_for_best_model='accuracy' means that the model with the highest accuracy on the validation set will be selected as the best model.","metadata":{"id":"0hq3f1JztJjm"}},{"cell_type":"markdown","source":"**greater_is_better:**\n\n\nThis parameter indicates whether a higher value of the evaluation metric is considered better for selecting the best model checkpoint. For example, greater_is_better=True means that higher accuracy values are preferred","metadata":{"id":"ZXwbR6AktRRp"}},{"cell_type":"markdown","source":"**Accelerate:**<br><br>\n\n- Suppose you're training a deep learning model to recognize images. This process involves lots of complex calculations.<br><br>\n- With accelerate, you can harness the power of specialized hardware like GPUs (Graphics Processing Units) to speed up these calculations.<br><br>\n- For example, if it takes 10 hours to train your model on a regular computer, accelerate might reduce it to just 2 hours on a GPU.<br><br>\n- Similarly, when you're running your trained model to make predictions, accelerate helps make those predictions faster, which is crucial for real-time applications like video processing or natural language understanding.<br><br>\nIn summary, bitsandbytes helps with data compression and decompression, while accelerate boosts the performance of deep learning tasks by leveraging specialized hardware.","metadata":{"id":"jvBTe_CjtvF2"}},{"cell_type":"code","source":"# from transformers import Trainer, TrainingArguments","metadata":{"id":"-VQLhl_C2dCW","execution":{"iopub.status.busy":"2024-06-28T17:30:42.421463Z","iopub.execute_input":"2024-06-28T17:30:42.421729Z","iopub.status.idle":"2024-06-28T17:30:42.470628Z","shell.execute_reply.started":"2024-06-28T17:30:42.421706Z","shell.execute_reply":"2024-06-28T17:30:42.469880Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# !pip install accelerate==0.21.0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MMBgjoVUxpMm","outputId":"f0fa2ff1-8278-4494-e97c-27e097f0e61e","execution":{"iopub.status.busy":"2024-06-28T17:30:42.471694Z","iopub.execute_input":"2024-06-28T17:30:42.471979Z","iopub.status.idle":"2024-06-28T17:30:42.481380Z","shell.execute_reply.started":"2024-06-28T17:30:42.471956Z","shell.execute_reply":"2024-06-28T17:30:42.480599Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# !pip install transformers[torch]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZW4uzDDxP6S1","outputId":"527f9bac-1215-445b-a6e9-66c423dbec6a","execution":{"iopub.status.busy":"2024-06-28T17:30:42.482606Z","iopub.execute_input":"2024-06-28T17:30:42.483233Z","iopub.status.idle":"2024-06-28T17:30:42.491861Z","shell.execute_reply.started":"2024-06-28T17:30:42.483176Z","shell.execute_reply":"2024-06-28T17:30:42.491049Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# !pip install accelerate -U","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ATxv8jUqQHrX","outputId":"42c5ae59-b1eb-442e-e39a-ea97c1c8216e","execution":{"iopub.status.busy":"2024-06-28T17:30:42.492872Z","iopub.execute_input":"2024-06-28T17:30:42.493128Z","iopub.status.idle":"2024-06-28T17:30:42.505077Z","shell.execute_reply.started":"2024-06-28T17:30:42.493106Z","shell.execute_reply":"2024-06-28T17:30:42.504276Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# !pip show transformers accelerate","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F5a8CryORHgz","outputId":"285bb42e-33fb-4c74-9dab-cf91da88bedb","execution":{"iopub.status.busy":"2024-06-28T17:30:42.506140Z","iopub.execute_input":"2024-06-28T17:30:42.506416Z","iopub.status.idle":"2024-06-28T17:30:42.515197Z","shell.execute_reply.started":"2024-06-28T17:30:42.506375Z","shell.execute_reply":"2024-06-28T17:30:42.514392Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# training_args=TrainingArguments(\n#     'my_trainer',                          #  Output directory where checkpoints and logs will be saved\n#     evaluation_strategy='epoch',           # Evaluate model at the end of each epoch\n#     save_strategy='epoch',                  # Save model checkpoint at the end of each epoch\n#     num_train_epochs=1,                     # Save model checkpoint at the end of each epoch\n# )","metadata":{"id":"CNeDypZym8Gx","execution":{"iopub.status.busy":"2024-06-28T17:30:42.516352Z","iopub.execute_input":"2024-06-28T17:30:42.517051Z","iopub.status.idle":"2024-06-28T17:30:42.525150Z","shell.execute_reply.started":"2024-06-28T17:30:42.517019Z","shell.execute_reply":"2024-06-28T17:30:42.524347Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# from transformers import AutoModelForSequenceClassification","metadata":{"id":"3Bk51ZoJqIOq","execution":{"iopub.status.busy":"2024-06-28T17:30:42.526218Z","iopub.execute_input":"2024-06-28T17:30:42.526471Z","iopub.status.idle":"2024-06-28T17:30:42.535117Z","shell.execute_reply.started":"2024-06-28T17:30:42.526448Z","shell.execute_reply":"2024-06-28T17:30:42.534268Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"**Automatic Model Selection:**\n\n- The AutoModelForSequenceClassification class automatically selects the appropriate pre-trained model for sequence classification tasks. Sequence classification tasks involve classifying sequences of tokens (such as sentences or documents) into one or more predefined categories.","metadata":{"id":"iVeOzydZ4mCL"}},{"cell_type":"code","source":"# checkpoint = \"bert-base-uncased\"","metadata":{"id":"0EDz4V645LpU","execution":{"iopub.status.busy":"2024-06-28T17:30:42.536285Z","iopub.execute_input":"2024-06-28T17:30:42.536621Z","iopub.status.idle":"2024-06-28T17:30:42.545153Z","shell.execute_reply.started":"2024-06-28T17:30:42.536590Z","shell.execute_reply":"2024-06-28T17:30:42.544334Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# model=AutoModelForSequenceClassification.from_pretrained(\n#     checkpoint,\n#     num_labels=2\n# )","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":138,"referenced_widgets":["3bad8fb68620442397a0e577d546d84b","dff067093ef44880a7620fcf4c955fab","2a49339d8b274a1dbabd552a26c54382","3491826687564fdea81e529b925f94c8","7124add7c0a34ca4ad80ba641696147e","3628892f75b54aa380203ac6717cb11a","80ee301624e248868e52e5048ecdecd3","d29e966264e64e269ef2822081570698","8be329b8ada34b49a597157f046b4e20","42e71d16e48542619601e64654a86c28","e164781c4a2d4b89926da165d694f27b","e2fbf210a594490382580d6d9238e01b","cffa7e53e5b84e90a7238750f31579db","d4aec5c6f40f4c4c855a5b5473140a92","5d8d70330ec94b1b9f71245bc498f9fc","e4cf98193dcd4a3aa566cf41ddb9f0a8","1b8c72741c144d3ca4850c3f776cd59e","facfe3f52b764b5e96f962f3617aae9c","6dde12dc74d349c0b7decb2d8bf34c9c","708e8e3323da4f35ad0678fb9084f28f","fa2ac77d4cc14619b04095e1550fdd1a","01d8592858fd4eb89414dd18c09ffeb4"]},"id":"rUl6YJKQqP3L","outputId":"f5b2943d-972d-4774-b851-af87396b8d8e","execution":{"iopub.status.busy":"2024-06-28T17:30:42.546194Z","iopub.execute_input":"2024-06-28T17:30:42.546516Z","iopub.status.idle":"2024-06-28T17:30:42.555513Z","shell.execute_reply.started":"2024-06-28T17:30:42.546485Z","shell.execute_reply":"2024-06-28T17:30:42.554669Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"**pretrained_model_name_or_path:**\n\nThis parameter specifies the identifier or path of the pre-trained model to load. It can be the name of a model available in the Hugging Face model hub (e.g., \"bert-base-uncased\") or the path to a directory containing a pre-trained model checkpoint.\n\n\n**num_labels:**\n\n\nThis parameter specifies the number of labels or classes in the classification task. For sequence classification tasks, the model's final layer typically has num_labels output units corresponding to the number of classes.\n\n\n**config:**\n\n\nThis parameter allows you to pass a model configuration object (PretrainedConfig) to the model. It can be used to customize the model's architecture and behavior.<br><br>\n\n\n\n\n\n\n**state_dict:**\n\n\nThis parameter allows you to directly initialize the model's parameters (weights and biases) from a PyTorch state_dict. It can be useful for loading custom or modified model weights.\ncache_dir: This parameter specifies the directory where downloaded model weights will be cached. If not provided, a default cache directory will be used.\n\n\nstate_dict Parameter:<br><br>\n- The state_dict parameter allows you to initialize a model's parameters (weights and biases) directly from a PyTorch state_dict. This is useful when you want to load custom or modified model weights into a pretrained model architecture.\n\n\n        import torch\n        from transformers import BertModel, BertTokenizer\n\n        # Instantiate a pretrained BERT model\n        model_name = \"bert-base-uncased\"\n        model = BertModel.from_pretrained(model_name)\n\n        # Suppose you have a custom state_dict with modified weights\n        custom_state_dict = torch.load(\"custom_bert_state_dict.pth\")\n\n        # Load the custom state_dict into the model\n        model.load_state_dict(custom_state_dict)\n\n        # Now `model` has been initialized with the custom weights from `custom_state_dict`\n\n\ncache_dir Parameter:<br><br>\n\n- The cache_dir parameter specifies the directory where downloaded model weights will be cached. If this parameter is not provided, a default cache directory will be used to store and retrieve pretrained model weights.\n\n\n      from transformers import BertTokenizer\n\n      # Specify a custom cache directory for model weights\n      custom_cache_dir = \"my_model_cache\"\n\n      # Instantiate a BERT tokenizer with a custom cache directory\n      tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", cache_dir=custom_cache_dir)\n\n      # Now the model weights downloaded by the tokenizer will be cached in `my_model_cache`\n\n\n**from_tf:**\n\n\nThis parameter specifies whether to load the model weights from a TensorFlow checkpoint if available. By default, it's set to False.<br><br>\n\n\n      from transformers import BertModel\n\n      # Example: Load a BERT model pretrained using TensorFlow into a PyTorch model\n      model_name_tf = \"bert-base-uncased-tf\"\n\n      # Instantiate a PyTorch model using the TensorFlow checkpoint\n      model = BertModel.from_pretrained(model_name_tf, from_tf=True)\n\n      # Now `model` is initialized with the model weights loaded from a TensorFlow checkpoint\n\n\n**force_download:** <br><br>\n\nThis parameter specifies whether to force re-download of model weights, even if they already exist in the cache directory. By default, it's set to False.\n\n\n\n\n**resume_download:**\n\n\nThis parameter specifies whether to resume interrupted downloads of model weights. By default, it's set to False.\nlocal_files_only: This parameter specifies whether to only load model weights from local files and skip downloading from remote sources. By default, it's set to False.","metadata":{"id":"5tI4T0qD89k9"}},{"cell_type":"markdown","source":"# BertForSequenceClassification\n\nThe `BertForSequenceClassification` model consists of the following components:\n\n### bert: BertModel\n\n- **embeddings: BertEmbeddings**\n  - `word_embeddings`: `Embedding(30522, 768, padding_idx=0)`\n  - `position_embeddings`: `Embedding(512, 768)`\n  - `token_type_embeddings`: `Embedding(2, 768)`\n  - `LayerNorm`: `LayerNorm((768,), eps=1e-12, elementwise_affine=True)`\n  - `dropout`: `Dropout(p=0.1, inplace=False)`\n\n- **encoder: BertEncoder**\n  - `layer`: `ModuleList` containing 12 `BertLayer` objects (indexed from 0 to 11)\n    - **BertLayer**\n      - **attention: BertAttention**\n        - **self: BertSelfAttention**\n          - `query`: `Linear(in_features=768, out_features=768, bias=True)`\n          - `key`: `Linear(in_features=768, out_features=768, bias=True)`\n          - `value`: `Linear(in_features=768, out_features=768, bias=True)`\n          - `dropout`: `Dropout(p=0.1, inplace=False)`\n        - **output: BertSelfOutput**\n          - `dense`: `Linear(in_features=768, out_features=768, bias=True)`\n          - `LayerNorm`: `LayerNorm((768,), eps=1e-12, elementwise_affine=True)`\n          - `dropout`: `Dropout(p=0.1, inplace=False)`\n      - **intermediate: BertIntermediate**\n        - `dense`: `Linear(in_features=768, out_features=3072, bias=True)`\n        - `intermediate_act_fn`: `GELUActivation()`\n      - **output: BertOutput**\n        - `dense`: `Linear(in_features=3072, out_features=768, bias=True)`\n        - `LayerNorm`: `LayerNorm((768,), eps=1e-12, elementwise_affine=True)`\n        - `dropout`: `Dropout(p=0.1, inplace=False)`\n\n- **pooler: BertPooler**\n  - `dense`: `Linear(in_features=768, out_features=768, bias=True)`\n  - `activation`: `Tanh()`\n\n### Additional Layers\n\n- **dropout**: `Dropout(p=0.1, inplace=False)`\n- **classifier**: `Linear(in_features=768, out_features=2, bias=True)`\n","metadata":{}},{"cell_type":"code","source":"# type(model)\n# transformers.models.bert.modeling_bert.BertForSequenceClassification","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":187},"id":"BhfEIUWrqhsZ","outputId":"0a037d64-f083-48dd-b3b8-ef97d8ed7132","execution":{"iopub.status.busy":"2024-06-28T17:30:42.556659Z","iopub.execute_input":"2024-06-28T17:30:42.557358Z","iopub.status.idle":"2024-06-28T17:30:42.565642Z","shell.execute_reply.started":"2024-06-28T17:30:42.557333Z","shell.execute_reply":"2024-06-28T17:30:42.564821Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# !pip install torchinfo","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JUlpx7O9qjd9","outputId":"18f5f948-90c7-4a8d-cbde-3840d5df24b2","execution":{"iopub.status.busy":"2024-06-28T17:30:42.566858Z","iopub.execute_input":"2024-06-28T17:30:42.567525Z","iopub.status.idle":"2024-06-28T17:30:42.576007Z","shell.execute_reply.started":"2024-06-28T17:30:42.567493Z","shell.execute_reply":"2024-06-28T17:30:42.575112Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# from torchinfo import summary\n# summary(model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UbMMNZ1-qnZD","outputId":"2757bfbd-16e6-4ce7-a0b4-3d3e49ec5d5e","execution":{"iopub.status.busy":"2024-06-28T17:30:42.576953Z","iopub.execute_input":"2024-06-28T17:30:42.577230Z","iopub.status.idle":"2024-06-28T17:30:42.586105Z","shell.execute_reply.started":"2024-06-28T17:30:42.577207Z","shell.execute_reply":"2024-06-28T17:30:42.585261Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"# BertForSequenceClassification Parameter Summary\n\n```plaintext\n================================================================================\nLayer (type:depth-idx)                                  Param #\n================================================================================\nBertForSequenceClassification                           --\n├─BertModel: 1-1                                        --\n│    └─BertEmbeddings: 2-1                              --\n│    │    └─Embedding: 3-1                              23,440,896\n│    │    └─Embedding: 3-2                              393,216\n│    │    └─Embedding: 3-3                              1,536\n│    │    └─LayerNorm: 3-4                              1,536\n│    │    └─Dropout: 3-5                                --\n│    └─BertEncoder: 2-2                                 --\n│    │    └─ModuleList: 3-6                             85,054,464\n│    └─BertPooler: 2-3                                  --\n│    │    └─Linear: 3-7                                 590,592\n│    │    └─Tanh: 3-8                                   --\n├─Dropout: 1-2                                          --\n├─Linear: 1-3                                           1,538\n================================================================================\nTotal params: 109,483,778\nTrainable params: 109,483,778\nNon-trainable params: 0\n================================================================================\n","metadata":{}},{"cell_type":"markdown","source":"\n<div style=\"border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; background-color: black; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: yellow; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\"> 🚀 Model Components </h1>\n</div>\n\n## Input Embeddings\n\nThe input to the model consists of sequences of tokens (words or subwords) from the input text. Each token is converted into a vector representation using an embedding layer. There are three types of embeddings:\n\n### Word Embeddings\n\nEach token is mapped to a vector representation using a pre-trained embedding matrix. This captures the meaning of individual words.\n\n### Position Embeddings\n\nEach token is assigned a position embedding vector, indicating its position in the sequence. This helps the model understand the order of tokens in the input.\n\n### Token Type Embeddings\n\nFor tasks involving multiple sequences (e.g., question answering), each sequence is assigned a token type embedding to distinguish between them.\n\n## Encoder Layers\n\nThe model consists of multiple layers of transformer blocks, called `BertLayers`. Each `BertLayer` contains two main components:\n\n### Self-Attention Mechanism\n\nThis mechanism allows the model to weigh the importance of each token in the sequence based on its relevance to other tokens. It attends to different parts of the input sequence when generating representations.\n\n### Feedforward Neural Networks\n\nAfter attending to relevant parts of the input sequence, the model passes the attended representations through feedforward neural networks to capture complex patterns and relationships in the data.\n\n## Pooling Layer\n\nAfter processing all the tokens in the sequence through the encoder layers, the model applies a pooling mechanism to aggregate the token-level representations into a single representation for the entire sequence. In this case, the pooling mechanism uses a fully connected layer followed by a non-linear activation function (Tanh) to compute the pooled representation.\n\n## Output Layer\n\nThe pooled representation is passed through a linear layer (classifier) to produce the final output. For sequence classification tasks, such as sentiment analysis or text categorization, the output layer has two units (`out_features=2`), representing the probabilities of belonging to each class (e.g., positive or negative sentiment).\n\n## Dropout\n\nDropout is applied throughout the model to prevent overfitting by randomly setting a fraction of input units to zero during training. This helps the model generalize better to unseen data.\n","metadata":{"id":"pj4CPHR06XJf"}},{"cell_type":"code","source":"# params_before=[]\n# for name,p in model.named_parameters():\n#   params_before.append(p.detach().cpu().numpy())","metadata":{"id":"iBD0QRflqxzI","execution":{"iopub.status.busy":"2024-06-28T17:30:42.591445Z","iopub.execute_input":"2024-06-28T17:30:42.591707Z","iopub.status.idle":"2024-06-28T17:30:42.597598Z","shell.execute_reply.started":"2024-06-28T17:30:42.591686Z","shell.execute_reply":"2024-06-28T17:30:42.596752Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"- After executing this code, params_before will contain the numpy representations of all the model parameters. These representations can be used for various purposes such as comparison, visualization, or tracking parameter changes during training.","metadata":{"id":"QF3rckDO7fXh"}},{"cell_type":"code","source":"# from transformers import Trainer","metadata":{"id":"39X0yjFUrMh8","execution":{"iopub.status.busy":"2024-06-28T17:30:42.598656Z","iopub.execute_input":"2024-06-28T17:30:42.598981Z","iopub.status.idle":"2024-06-28T17:30:42.607583Z","shell.execute_reply.started":"2024-06-28T17:30:42.598957Z","shell.execute_reply":"2024-06-28T17:30:42.606900Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# from datasets import load_metric","metadata":{"id":"k79oq8JRrQxf","execution":{"iopub.status.busy":"2024-06-28T17:30:42.608606Z","iopub.execute_input":"2024-06-28T17:30:42.608909Z","iopub.status.idle":"2024-06-28T17:30:42.618163Z","shell.execute_reply.started":"2024-06-28T17:30:42.608886Z","shell.execute_reply":"2024-06-28T17:30:42.617343Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# metric=load_metric('glue','sst2')","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":180,"referenced_widgets":["24e2a78ffa8d413f8362ff903770bfed","5670c8d923aa4254bfc73b7dca8c8cc2","b097fbf3bf3b4cb3965af6f51f186154","55b871455d7545b185da54895d872b9e","3ff76d84b555409492e8ba9886a4eafe","53d66e1354bd4ccea309023394c12919","ba2c814420e14e9aa79123a93557a65f","7fd67eaad22a4df5a597ed6d01ced270","dd36a59eda674652a2ea227823642d3c","962a0ffb2a8d4c949b7c4c8aeb435e95","6ac191dc4d744a24966a1775a10c4be4"]},"id":"xB0cHwL4rY0H","outputId":"2cebe552-8521-4000-cf58-e0499f014623","execution":{"iopub.status.busy":"2024-06-28T17:30:42.619202Z","iopub.execute_input":"2024-06-28T17:30:42.619451Z","iopub.status.idle":"2024-06-28T17:30:42.628710Z","shell.execute_reply.started":"2024-06-28T17:30:42.619429Z","shell.execute_reply":"2024-06-28T17:30:42.627885Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# metric.compute(predictions=[1,0,1],references=[1,0,0])\n# {'accuracy': 0.6666666666666666}","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"89PYzJzarf13","outputId":"36e6345d-3c8b-4e38-b08f-720b61c6c7cd","execution":{"iopub.status.busy":"2024-06-28T17:30:42.629655Z","iopub.execute_input":"2024-06-28T17:30:42.629988Z","iopub.status.idle":"2024-06-28T17:30:42.638538Z","shell.execute_reply.started":"2024-06-28T17:30:42.629954Z","shell.execute_reply":"2024-06-28T17:30:42.637822Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# def compute_metrics(logits_and_labels):\n#   logits,labels=logits_and_labels\n#   predictions=np.argmax(logits,axis=1)\n#   return metric.compute(predictions=predictions,references=labels)","metadata":{"id":"n2K23U2zruHZ","execution":{"iopub.status.busy":"2024-06-28T17:30:42.639667Z","iopub.execute_input":"2024-06-28T17:30:42.639989Z","iopub.status.idle":"2024-06-28T17:30:42.648934Z","shell.execute_reply.started":"2024-06-28T17:30:42.639965Z","shell.execute_reply":"2024-06-28T17:30:42.648203Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# trainer=Trainer(\n#     model,\n#     training_args,\n#     train_dataset=tokenized_datasets['train'],\n#     eval_dataset=tokenized_datasets['validation'],\n#     tokenizer=tokenizer,\n#     compute_metrics=compute_metrics\n# )","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YFy5wSQtsQVC","outputId":"7aaedbc1-ab3e-4c94-91bb-3e71cf6aaf2b","execution":{"iopub.status.busy":"2024-06-28T17:30:42.650036Z","iopub.execute_input":"2024-06-28T17:30:42.650283Z","iopub.status.idle":"2024-06-28T17:30:42.658817Z","shell.execute_reply.started":"2024-06-28T17:30:42.650261Z","shell.execute_reply":"2024-06-28T17:30:42.658034Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# trainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"vbZoZ4_Xs1xw","outputId":"c004f72e-38cb-477c-f34a-bc1bba8ab0bb","execution":{"iopub.status.busy":"2024-06-28T17:30:42.659924Z","iopub.execute_input":"2024-06-28T17:30:42.660317Z","iopub.status.idle":"2024-06-28T17:30:42.668607Z","shell.execute_reply.started":"2024-06-28T17:30:42.660285Z","shell.execute_reply":"2024-06-28T17:30:42.667826Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Training Log\n\n```plaintext\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\nwandb: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\nwandb: You can find your API key in your browser here: https://wandb.ai/authorize\nwandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\n  ········································\nwandb: Appending key for api.wandb.ai to your netrc file: /root/.netrc\nwandb version 0.17.3 is available! To upgrade, please run: $ pip install wandb --upgrade\nTracking run with wandb version 0.17.0\nRun data is saved locally in /kaggle/working/wandb/run-20240628_165911-m1bzgk1r\nSyncing run jumping-sunset-7 to Weights & Biases (docs)\nView project at https://wandb.ai/mustafashoukat-email-VU/huggingface\nView run at https://wandb.ai/mustafashoukat-email-VU/huggingface/runs/m1bzgk1r\nYou're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n [4210/4210 11:58, Epoch 1/1]\nEpoch\tTraining Loss\tValidation Loss\tAccuracy\n1\t0.167200\t0.223724\t0.932339\nTrainOutput(global_step=4210, training_loss=0.21758312035059985, metrics={'train_runtime': 746.252, 'train_samples_per_second': 90.25, 'train_steps_per_second': 5.642, 'total_flos': 1219601963798400.0, 'train_loss': 0.21758312035059985, 'epoch': 1.0})\n","metadata":{}},{"cell_type":"markdown","source":"**global_step:**\n\n\n\n- This represents the total number of optimization steps (parameter updates) performed during training. Each optimization step corresponds to one batch of training data processed.\n\n\n\n**training_loss:**\n\n\n\n- This is the average loss value computed during the training process. It represents how well the model's predictions match the ground truth labels on the training data. Lower values indicate better performance.\n\n\n\n**metrics:**\n\n\n\n- This dictionary contains additional metrics and information related to the training process. Let's break down each metric:\n\n\n- **train_runtime:**\n\n\n- This is the total runtime of the training process in seconds. It represents the amount of time taken to complete the training.\n\n\n- **train_samples_per_second:**\n\n\n- This metric indicates the number of training samples processed per second. It represents the training speed or throughput of the model.\n\n\n- **train_steps_per_second:**\n\n\n- This metric indicates the number of training steps (parameter updates) performed per second. It represents the training speed in terms of optimization steps.\n\n\n**total_flos:**\n\n\n\n- This metric represents the total number of floating-point operations (FLOPs) executed during training. FLOPs are a measure of computational complexity and represent the total amount of arithmetic operations performed by the model.\n\n\n**train_loss:**\n\n\n\n- This is the same as training_loss. It represents the average loss value computed during training.\n\n\n**epoch:**\n\n\n- This indicates the current epoch of training. In your case, it shows 1.0, which means that one epoch of training has been completed.","metadata":{"id":"YLsrnWHP-cwD"}},{"cell_type":"code","source":"# trainer.save_model('my_model')","metadata":{"id":"ezBPd5DGs44s","execution":{"iopub.status.busy":"2024-06-28T17:30:42.669600Z","iopub.execute_input":"2024-06-28T17:30:42.670309Z","iopub.status.idle":"2024-06-28T17:30:42.678525Z","shell.execute_reply.started":"2024-06-28T17:30:42.670284Z","shell.execute_reply":"2024-06-28T17:30:42.677693Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# from transformers import pipeline","metadata":{"id":"mFh3SrmAtDIw","execution":{"iopub.status.busy":"2024-06-28T17:30:42.679606Z","iopub.execute_input":"2024-06-28T17:30:42.679912Z","iopub.status.idle":"2024-06-28T17:30:42.687858Z","shell.execute_reply.started":"2024-06-28T17:30:42.679886Z","shell.execute_reply":"2024-06-28T17:30:42.686947Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# my_model=pipeline('text-classification',model='my_model',device=0)","metadata":{"id":"Q906pxkNtIOy","execution":{"iopub.status.busy":"2024-06-28T17:30:42.688992Z","iopub.execute_input":"2024-06-28T17:30:42.689250Z","iopub.status.idle":"2024-06-28T17:30:42.698277Z","shell.execute_reply.started":"2024-06-28T17:30:42.689228Z","shell.execute_reply":"2024-06-28T17:30:42.697416Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# my_model('this movie is beautiful')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5MGratJZtWp8","outputId":"0aa3e38b-f4f5-40c3-c3b8-f72bf34d40a6","execution":{"iopub.status.busy":"2024-06-28T17:30:42.699296Z","iopub.execute_input":"2024-06-28T17:30:42.699890Z","iopub.status.idle":"2024-06-28T17:30:42.708347Z","shell.execute_reply.started":"2024-06-28T17:30:42.699864Z","shell.execute_reply":"2024-06-28T17:30:42.707514Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; background-color: black; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: yellow; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\"> 🚀 Challenges of Training Large Language Models on Google Colab's GPU 🧠</h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"- Training large models like LLaMA2, Zephyr, or Mistral on Google Colab's GPU can be challenging due to the limited resources and memory constraints. Here's a brief analysis of each model's requirements:<br><br>\n\n**LLaMA2:**  \n\nThis model has approximately 1.4 billion parameters, which requires a significant amount of memory and computational resources.<br><br>\n\n\n**Zephyr:**\n\nZephyr is a large language model with around 2.5 billion parameters, making it even more resource-intensive than LLaMA2.<br><br>\n\n**Mistral:**\n\nMistral is a massive model with around 5 billion parameters, which is one of the largest language models available.<br><br>\n\n\nGoogle Colab's GPU resources are limited, and training these models might not be feasible or would require significant modifications to the training script. Here are some limitations to consider:<br><br>\n\n**GPU Memory:**\n\nColab's GPU has 16 GB of VRAM, which might not be enough to hold the model's parameters and the input data.<br><br>\n\n\n**Compute Resources:**\n\nColab's GPU has a limited number of CUDA cores and memory bandwidth, which can slow down the training process.<br><br>\n\nIf you still want to try training these models on Colab, here are some possible workarounds:<br><br>\n\n**Model parallelism:**\n\nYou can try to split the model across multiple GPUs using model parallelism techniques, such as torch.distributed or transformers' built-in parallelism features. This would require significant modifications to the training script.<br><br>\n\n**Gradient checkpointing:**\n\nYou can use gradient checkpointing to reduce the memory requirements during training. This technique saves only the gradients of the model's parameters at certain intervals, reducing the memory footprint.<br><br>\n\n\n**Mixed precision training:**\n\nYou can use mixed precision training, which uses lower precision data types (e.g., float16) for the model's parameters and activations, reducing the memory requirements.\nHowever, even with these workarounds, training these large models on Colab's GPU might not be feasible or would require an impractically long time.\n\nEstimated training time on Colab's GPU:\n\nAssuming you can modify the training script to accommodate the model's size, here are rough estimates of the training time on Colab's GPU:\n\n      LLaMA2: 1-2 weeks (depending on the batch size and sequence length)\n      Zephyr: 2-4 weeks (depending on the batch size and sequence length)\n      Mistral: 4-8 weeks (depending on the batch size and sequence length)\n\n\nKeep in mind that these estimates are rough and might not be accurate, as the training time depends on many factors, including the model's architecture, dataset size, batch size, and sequence length.<br><br>\n\n**Alternate options:**\n\nIf you cannot train these models on Colab's GPU, consider the following alternatives:\n\n**Cloud services:**\n- Use cloud services like AWS, Google Cloud, or Microsoft Azure, which offer more powerful GPU instances with larger memory and compute resources.<br><br>\n\n\n**Local machine:**\n\n- If you have a powerful local machine with a high-end GPU (e.g., NVIDIA V100 or A100), you can train the models locally.<br><br>\n\n\n**Distributed training:**\n\n- Use distributed training frameworks like transformers' Trainer with DistributedDataParallel or torch.distributed to train the models on multiple machines or GPUs.<br><br>\n\n**Pre-trained models:**\n\n- If you don't need to fine-tune the models from scratch, you can use pre-trained models available on the Hugging Face model hub, which can save you a significant amount of time and resources.","metadata":{"id":"95O_WLgZiGL1"}},{"cell_type":"markdown","source":"<div style=\"border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; background-color: black; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: yellow; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\"> 🚀 Challenges of Training Large Language Models on Google Colab's GPU 🧠</h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"**Transfer Learning:**<br><br>\n\n\n- In transfer learning, a pre-trained model (often trained on a large dataset) is used as a starting point for a new task. The weights of the pre-trained model are initialized based on its previous training.\nDuring transfer learning, the model is typically adapted to the new task by adjusting its weights using a smaller learning rate than during the initial training. This allows the model to fine-tune its parameters to better suit the characteristics of the new task.<br><br>\n- The degree of adjustment to the weights in transfer learning may vary depending on the similarity between the original task and the new task. If the tasks are closely related, the weights may require only minor adjustments to perform well on the new task.<br><br>\n\n\n**Fine-Tuning:**<br><br>\n\n\n- Fine-tuning is a specific form of transfer learning where the pre-trained model's parameters are further adjusted (fine-tuned) on a new dataset or task.<br><br>\n\n- In fine-tuning, the weights of the pre-trained model are updated more extensively compared to transfer learning. The entire model (or a portion of it) is trained on the new dataset, and the learning rate used for updating the weights may be smaller than during the initial training but larger than in transfer learning.<br><br>\n\n\n- Fine-tuning allows the model to adapt more closely to the specifics of the new task, potentially resulting in better performance on the task compared to transfer learning alone.<br><br>\n\n\nIn summary, while both transfer learning and fine-tuning involve adjusting the weights of a pre-trained model for a new task, fine-tuning typically involves more extensive weight adjustments and training on the new dataset. Transfer learning may involve less extensive adjustments, but it still adapts the pre-trained model to the characteristics of the new task to some degree.\n\n\n<div style=\"border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; background-color: black; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: yellow; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\"> 🚀🎯 Difference Between Fine-Tuning and Parameter-Efficient Fine-Tuning 🔄</h1>\n</div>\n\n\n# Transfer Learning\n\n- **Uses**: A pre-trained model (weights and architecture) trained on a large dataset (source task) for a new task (target task).\n- **Key Point**: Freezes most of the pre-trained model's parameters, only training a small subset (usually the final layers) on the new data.\n- **Benefit**: Faster training, leverages learned features, good for tasks with limited data.\n\n# Fine-Tuning\n\n- **Also leverages**: A pre-trained model for a new task.\n- **Key Point**: Trains all the parameters of the pre-trained model on the new data.\n- **Benefit**: Allows for more significant adaptation to the new task, potentially higher performance compared to transfer learning.\n- **Drawback**: Can be computationally expensive, potentially prone to overfitting with small datasets.\n\n# Parameter-Efficient Fine-Tuning (PEFT)\n\n- **A specific strategy**: Within fine-tuning.\n- **Key Point**: Focuses on training only a subset of the pre-trained model's parameters, often identified through techniques like saliency maps or gradient analysis.\n- **Benefit**: Reduces computational cost compared to full fine-tuning while achieving comparable performance in some cases.\n\n[PEFT Paper on GitHub](https://github.com/huggingface/peft) \n\n![Transfer Learning Image](https://assets.isu.pub/document-structure/230601111519-67cde4fe1c7eba3b19bcb148f484d14a/v1/5875b3596bd87a85183be5a114dd4fd0.jpeg)\n","metadata":{"id":"Ls11aU47Qg8_"}},{"cell_type":"markdown","source":"- Fine-tuning and parameter-efficient fine-tuning are two approaches used in machine learning to improve the performance of pre-trained models on a specific task.<br><br>\n\n- Fine-tuning is taking a pre-trained model and training it further on a new task with new data. The entire pre-trained model is usually trained in fine-tuning, including all its layers and parameters. This process can be computationally expensive and time-consuming, especially for large models.<br><br>\n\n- On the other hand, parameter-efficient fine-tuning is a method of fine-tuning that focuses on training only a subset of the pre-trained model’s parameters. This approach involves identifying the most important parameters for the new task and only updating those parameters during training. Doing so, PEFT can significantly reduce the computation required for fine-tuning.","metadata":{"id":"VmbpWeQBRrh5"}},{"cell_type":"markdown","source":"\n<div style=\"border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; background-color: black; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: yellow; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\"> 🚀 🔧 Parameter-Efficient Fine-Tuning Techniques 🛠️ 🧠</h1>\n</div>","metadata":{"id":"Gv4SXvCETF4Y"}},{"cell_type":"markdown","source":"**Adapter**<br><br>\n\n- Adapters are a special type of submodule that can be added to pre-trained language models to modify their hidden representation during fine-tuning. By inserting adapters after the multi-head attention and feed-forward layers in the transformer architecture, we can update only the parameters in the adapters during fine-tuning while keeping the rest of the model parameters frozen.\n\n- Adopting adapters can be a straightforward process. All that is required is to add adapters into each transformer layer and place a classifier layer on top of the pre-trained model. By updating the parameters of the adapters and the classifier head, we can improve the performance of the pre-trained model on a particular task without updating the entire model. This approach can save time and computational resources while still producing impressive results.","metadata":{"id":"FA_b2eI4TN4Z"}},{"cell_type":"markdown","source":"**LoRA**<br><br>\n\n\n- Low-Rank Adaptation (LoRA) of large language models is another approach in the area of fine-tuning models for specific tasks or domains. Similar to the adapters, LoRA is also a small trainable submodule that can be inserted into the transformer architecture. It involves freezing the pre-trained model weights and injecting trainable rank decomposition matrices into each layer of the transformer architecture, greatly diminishing the number of trainable parameters for downstream tasks. This method can minimize the number of trainable parameters by up to 10,000 times and the GPU memory necessity by 3 times while still performing on par or better than fine-tuning model quality on various tasks. LoRA also allows for more efficient task-switching, lowering the hardware barrier to entry, and has no additional inference latency compared to other methods.\n\n**QLoRA**<br><br>\n\n- QLoRA (Quantized Low-Rank Adaptation) is an advanced fine-tuning approach that combines quantization with LoRA. It reduces the model's precision (e.g., from 32-bit to 8-bit) to save memory and computational resources, while also using low-rank adaptation to inject small trainable modules into the transformer architecture. This results in significant reductions in the number of trainable parameters and memory requirements, enabling efficient fine-tuning on downstream tasks with minimal performance loss.\n\n\n### All Fine Tuning Techniques \n[PEFT Paper on GitHub](https://github.com/huggingface/peft)\n","metadata":{"id":"pEaM0pfaTX3x"}},{"cell_type":"markdown","source":"<div style=\"border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; background-color: black; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: yellow; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\"> 🚀 🔧 Fine-Tune LLaMA 3 with ORPO 🚀 🧠</h1>\n</div>","metadata":{"id":"uLHnhv6RGT_Q"}},{"cell_type":"markdown","source":"ORPO is a new exciting fine-tuning technique that combines the traditional supervised fine-tuning and preference alignment stages into a single process. This reduces the computational resources and time required for training. Moreover, empirical results demonstrate that ORPO outperforms other alignment methods on various model sizes and benchmarks.","metadata":{"id":"_AvpZoP_GmYr"}},{"cell_type":"markdown","source":"- There are now many methods to align large language models (LLMs) with human preferences. Reinforcement learning with human feedback (RLHF) was one of the first and brought us ChatGPT, but RLHF is very costly. DPO**(Differentiable Preference Optimization)**, IPO**(Interactive Preference Optimization)**, and KTO **(Knowledge Transfer Optimization)** are notably cheaper than RLHF as they don’t need a reward model.<br><br>\n\n- While DPO and IPO are cheaper, they still require to train two different models. One model for the supervised fine-tuning (SFT) step, i.e., training the model to answer instructions, and then the model to align with human preferences using the SFT model for initialization and as a reference.<br><br>\n\n- ORPO is yet another new method for LLM alignment but this one doesn’t even need the SFT model. With ORPO, the LLM jointly learns to answer instructions and human preferences.","metadata":{"id":"LmMJ88NHHRWr"}},{"cell_type":"markdown","source":"[ORPO: Monolithic Preference Optimization without Reference Model](https://arxiv.org/abs/2403.07691)","metadata":{"id":"j41OFcG6IJJl"}},{"cell_type":"markdown","source":"<div style=\"border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; background-color: black; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: yellow; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\"> 🚀 ORPO</h1>\n</div>","metadata":{}},{"cell_type":"markdown","source":"\n\nInstruction tuning and preference alignment are essential techniques for adapting Large Language Models (LLMs) to specific tasks. Traditionally, this involves a multi-stage process: 1/ Supervised Fine-Tuning (SFT) on instructions to adapt the model to the target domain, followed by 2/ preference alignment methods like Reinforcement Learning with Human Feedback (RLHF) or Direct Preference Optimization (DPO) to increase the likelihood of generating preferred responses over rejected ones.\n\n## ORPO: Monolithic Preference Optimization without Reference Model\n\n[ORPO: Monolithic Preference Optimization without Reference Model](https://arxiv.org/abs/2403.07691)\n\n![ORPO](https://th.bing.com/th/id/OIP.PhVMLEGxFypiLHcfdfD9IwHaCz?rs=1&pid=ImgDetMain)","metadata":{"id":"zgizHaw2JNjD"}},{"cell_type":"markdown","source":"However, researchers have identified a limitation in this approach. While SFT effectively adapts the model to the desired domain, it inadvertently increases the probability of generating undesirable answers alongside preferred ones. This is why the preference alignment stage is necessary to widen the gap between the likelihoods of preferred and rejected outputs.\n\n\n<div style=\"border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; background-color: black; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: yellow; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\"> 🚀 ORPO: Monolithic Preference Optimization without Reference Model </h1>\n</div>\n\n[ORPO: Monolithic Preference Optimization without Reference Model](https://arxiv.org/abs/2403.07691)\n\n\n**Brief Description:**\nORPO (Monolithic Preference Optimization without Reference Model) is a method for optimizing preferences in machine learning models without relying on a reference model. It aims to streamline the optimization process and improve efficiency. The PEFT (Parameter-Efficient Fine-Tuning) approach is used to fine-tune large models with fewer parameters, enhancing their performance while reducing computational costs.\n","metadata":{"id":"GlyjVj_qJ24T"}},{"cell_type":"markdown","source":"Introduced by Hong and Lee (2024), ORPO offers an elegant solution to this problem by combining instruction tuning and preference alignment into a single, monolithic training process.","metadata":{"id":"4jcX1RP6KPRw"}},{"cell_type":"code","source":"# !pip install -U transformers datasets accelerate peft trl bitsandbytes wandb","metadata":{"id":"y08Ea7IeLCKw","execution":{"iopub.status.busy":"2024-06-28T17:30:42.709496Z","iopub.execute_input":"2024-06-28T17:30:42.709889Z","iopub.status.idle":"2024-06-28T17:30:42.718308Z","shell.execute_reply.started":"2024-06-28T17:30:42.709864Z","shell.execute_reply":"2024-06-28T17:30:42.717409Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; background-color: black; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: yellow; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\"> 🚀 Accelerate</h1>\n</div>\n","metadata":{}},{"cell_type":"markdown","source":"\nAccelerate is a library that provides a set of tools to accelerate the training of deep learning models. It's designed to work seamlessly with popular deep learning frameworks like PyTorch and TensorFlow.\n\nAccelerate provides several features to speed up training, including:\n\n**Mixed precision training:**\n\n- Accelerate allows you to use lower precision data types (e.g., float16) for model weights and activations, which can significantly reduce memory usage and improve training speed.<br><br>\n\n\n**Gradient checkpointing:**\n\n- Accelerate provides a gradient checkpointing mechanism that allows you to store only the gradients of the model's parameters at certain intervals, reducing memory usage and improving training speed.<br><br>\n\n\n**Distributed training:**\n\n- Accelerate provides a distributed training framework that allows you to scale your training process across multiple machines, making it ideal for large-scale deep learning models","metadata":{"id":"jE9VZBwGMLx8"}},{"cell_type":"markdown","source":"<div style=\"border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; background-color: black; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: yellow; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\"> 🚀 Wandb</h1>\n</div>\n\n","metadata":{}},{"cell_type":"markdown","source":"\n- The Weights & Biases library (wandb) is a tool for visualizing and tracking machine learning experiments. It provides features for logging model training metrics, visualizing training progress with interactive charts, and comparing experiments across different runs. It's commonly used by researchers and practitioners to monitor and analyze the performance of their machine learning models.","metadata":{"id":"kVPOARbET2_U"}},{"cell_type":"markdown","source":"<div style=\"border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; background-color: black; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: yellow; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\"> 🚀 TRL - Transformer Reinforcement Learning</h1>\n</div>\n\n","metadata":{}},{"cell_type":"markdown","source":"\n- TRL is a full stack library where we provide a set of tools to train transformer language models with Reinforcement Learning, from the Supervised Fine-tuning step (SFT), Reward Modeling step (RM) to the Proximal Policy Optimization (PPO) step. <br><br>\n\n\n\n**Model Classes:**\n\nA brief overview of what each public model class does.<br><br>\n\n\n**SFTTrainer:**\n\nSupervise Fine-tune your model easily with SFTTrainer<br><br>\n\n\n**RewardTrainer:**\n\nTrain easily your reward model using RewardTrainer.<br><br>\n\n\n**PPOTrainer:**\n\nFurther fine-tune the supervised fine-tuned model using PPO algorithm\nBest-of-N Sampling: Use best of n sampling as an alternative way to sample predictions from your active model<br><br>\n\n\n**DPOTrainer:**\n\n\nDirect Preference Optimization training using DPOTrainer.\nTextEnvironment: Text environment to train your model using tools with RL.","metadata":{"id":"Jmzum4xQUXBN"}},{"cell_type":"markdown","source":"<div style=\"border-radius: 20px; border: 2px solid #64B5F6; padding: 15px; background-color: black; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: yellow; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\"> 🚀 BitsAndBytes</h1>\n</div>\n","metadata":{"id":"dlYFcYpaXS61"}},{"cell_type":"markdown","source":"**Optimizers:**<br><br>\n\n\n- Optimizers are algorithms used to adjust the parameters of a machine learning model during training in order to minimize the error or loss function. These algorithms play a crucial role in the training process by determining how the model's parameters are updated based on the gradients of the loss function with respect to those parameters.<br><br>\n\n- Common optimization algorithms include stochastic gradient descent (SGD), Adam, RMSprop, and Adagrad, among others. Each optimizer has its own update rules and hyperparameters that influence the training dynamics and convergence properties of the model.<br><br>\n\n\nExample:\n\nSuppose you're training a neural network for image classification. During each training iteration, the optimizer computes the gradients of the loss function with respect to the model's parameters and updates the parameters accordingly to minimize the classification error.","metadata":{"id":"zVGKupdsXW-t"}},{"cell_type":"markdown","source":"**Precision:**<br><br>\n\n\n- Precision refers to the level of numerical accuracy or representation used to store and process data in a computational system. In the context of machine learning and optimization, precision often refers to the number of bits used to represent numerical values, particularly floating-point numbers.<br><br>\n\n- Higher precision allows for greater numerical accuracy but requires more memory and computational resources. Conversely, lower precision reduces memory usage and computational overhead but may introduce quantization errors or numerical instability.<br><br>\n\n\n- Precision is commonly expressed in terms of the number of bits used to represent numerical values, such as 16-bit (half precision), 32-bit (single precision), or 64-bit (double precision).<br><br>\n\n\nExample:\n\nIn training neural networks, the weights, biases, and gradients are typically represented using 32-bit floating-point numbers (float32) for high precision. However, for memory-constrained environments or specialized hardware accelerators, lower precision formats like 16-bit floating-point numbers (float16) or even 8-bit integers (int8) may be used to reduce memory consumption and improve computational efficiency while still achieving acceptable performance.","metadata":{"id":"4muqdwNBX2fS"}},{"cell_type":"markdown","source":"## **BitsAndBytes Types**","metadata":{"id":"ohOFQyldY43Y"}},{"cell_type":"markdown","source":"- The bitsandbytes library provides functionalities for reducing memory consumption in large language models (LLMs) using k-bit quantization techniques. <br><br>\n\nLet's break down each feature and explain them with examples:<br><br>\n\n**8-bit Optimizers:**<br><br>\n\n\n- This feature utilizes block-wise quantization to maintain 32-bit performance while significantly reducing memory consumption. It optimizes the memory usage of the optimizer during training.\n\n\nExample:\n\nSuppose you're training a large language model using PyTorch with a 32-bit optimizer. By using bitsandbytes's 8-bit optimizer feature, you can quantize the optimizer to use only 8 bits for certain operations, dramatically reducing memory usage without sacrificing performance.<br><br>\n\n\n**LLM.Int() or 8-bit Quantization for Inference:**<br><br>\n\n\n- This feature enables large language model inference with only half the required memory and without any performance degradation. It achieves this by quantizing most features to 8 bits and separately treating outliers with 16-bit matrix multiplication.\n\nExample:\n\nYou have a pre-trained language model like BERT, which requires significant memory for inference due to its large size. By applying bitsandbytes's LLM.Int() feature, you can quantize the model's parameters to 8 bits, reducing the memory required for inference while maintaining performance.<br><br>\n\n\n**QLoRA or 4-bit Quantization for Training:**<br><br>\n\n\n- This feature enables large language model training with memory-saving techniques that do not compromise performance. It quantizes the model to 4 bits and inserts a small set of trainable low-rank adaptation (LoRA) weights to allow training.\n\n\nExample:\n\nYou want to fine-tune a large language model on a specific task, but memory constraints make it challenging. By using bitsandbytes's QLoRA feature, you can quantize the model to 4 bits and introduce LoRA weights, reducing memory usage during training without sacrificing performance.","metadata":{"id":"vxER59qSYvfz"}},{"cell_type":"code","source":"# import gc\n# import os\n\n# import torch\n# import wandb\n# from datasets import load_dataset\n# from google.colab import userdata\n# from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n# from transformers import (\n#     AutoModelForCausalLM,\n#     AutoTokenizer,\n#     BitsAndBytesConfig,\n#     TrainingArguments,\n#     pipeline,\n# )\n# from trl import ORPOConfig, ORPOTrainer, setup_chat_format\n\n# wb_token = userdata.get('wandb')\n# wandb.login(key=wb_token)\n","metadata":{"id":"Dbp9YLUtZ8Ay","execution":{"iopub.status.busy":"2024-06-28T17:30:42.719479Z","iopub.execute_input":"2024-06-28T17:30:42.719889Z","iopub.status.idle":"2024-06-28T17:30:42.728484Z","shell.execute_reply.started":"2024-06-28T17:30:42.719851Z","shell.execute_reply":"2024-06-28T17:30:42.727661Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"# if torch.cuda.get_device_capability()[0] >= 8:\n#     !pip install -qqq flash-attn\n#     attn_implementation = \"flash_attention_2\"\n#     torch_dtype = torch.bfloat16\n# else:\n#     attn_implementation = \"eager\"\n#     torch_dtype = torch.float16\n","metadata":{"id":"ChevT-dtaNEc","execution":{"iopub.status.busy":"2024-06-28T17:30:42.729434Z","iopub.execute_input":"2024-06-28T17:30:42.729683Z","iopub.status.idle":"2024-06-28T17:30:42.742189Z","shell.execute_reply.started":"2024-06-28T17:30:42.729661Z","shell.execute_reply":"2024-06-28T17:30:42.741204Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"- The condition torch.cuda.get_device_capability()[0] >= 8 checks if the CUDA compute capability of the GPU is greater than or equal to 8.<br><br>\n\n- CUDA capability 8 refers to GPUs with the Ampere architecture, which introduced significant improvements in performance, efficiency, and feature support compared to previous architectures.","metadata":{"id":"NFMb13Jhb279"}},{"cell_type":"markdown","source":"- **torch.float16** represents 16-bit floating-point numbers (half precision), which offer lower precision but require less memory compared to 32-bit floating-point numbers (float32).<br><br>\n\n\n- **torch.bfloat16** represents 16-bit floating-point numbers using the bfloat16 format, which provides greater precision than float16 for certain operations while still offering memory savings compared to float32.","metadata":{"id":"nnxdhSs4cCfN"}},{"cell_type":"markdown","source":"In the following, we will load the Llama 3 8B model in 4-bit precision thanks to bitsandbytes. We then set the LoRA configuration using PEFT for QLoRA. I'm also using the convenient setup_chat_format() function to modify the model and tokenizer for ChatML support. It automatically applies this chat template, adds special tokens, and resizes the model's embedding layer to match the new vocabulary size.","metadata":{"id":"rZCQp1j3cYiZ"}},{"cell_type":"code","source":"# # Model\n# base_model = \"meta-llama/Meta-Llama-3-8B\"\n# new_model = \"OrpoLlama-3-8B\"\n\n# # QLoRA config\n# bnb_config = BitsAndBytesConfig(\n#     load_in_4bit=True,\n#     bnb_4bit_quant_type=\"nf4\",\n#     bnb_4bit_compute_dtype=torch_dtype,\n#     bnb_4bit_use_double_quant=True,\n# )\n\n# # LoRA config\n# peft_config = LoraConfig(\n#     r=16,\n#     lora_alpha=32,\n#     lora_dropout=0.05,\n#     bias=\"none\",\n#     task_type=\"CAUSAL_LM\",\n#     target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n# )\n\n# # Load tokenizer\n# tokenizer = AutoTokenizer.from_pretrained(base_model)\n\n# # Load model\n# model = AutoModelForCausalLM.from_pretrained(\n#     base_model,\n#     quantization_config=bnb_config,\n#     device_map=\"auto\",\n#     attn_implementation=attn_implementation\n# )\n# model, tokenizer = setup_chat_format(model, tokenizer)\n# model = prepare_model_for_kbit_training(model)\n","metadata":{"id":"U55DLNV0cgZL","execution":{"iopub.status.busy":"2024-06-28T17:30:42.743290Z","iopub.execute_input":"2024-06-28T17:30:42.743624Z","iopub.status.idle":"2024-06-28T17:30:42.751378Z","shell.execute_reply.started":"2024-06-28T17:30:42.743600Z","shell.execute_reply":"2024-06-28T17:30:42.750514Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":"[Link to understand Quantization](https://www.kaggle.com/code/lorentzyeung/what-s-4-bit-quantization-how-does-it-help-llama2)","metadata":{"id":"EtcjkTTDeVfz"}},{"cell_type":"markdown","source":"**bnb_4bit_quant_type:**\n\n- NF4 (NormalFloat) is a 4-bit data type used in machine learning, which normalizes each weight to a value between -1 and 1 for a more accurate representation of the lower precision weight. It is an enhancement of the Quantile Quantization technique and has shown better results than both 4-bit Integers and 4-bit Floats. NF4 can also be coupled with Double-Quantization (DQ) for higher compression while maintaining performance.<br><br>\n\n**bnb_4bit_use_double_quant**\n\n\n- DQ encompasses two quantization phases; initially, quantization constants are processed, which are then used as inputs for the subsequent quantization, yielding FP32 and FP8 values. This method avoids any performance drop, while saving an average of about 0.37 bits per parameter (approximately 3 GB for a 65B model). The recent integration of bitsandbytes, which incorporates findings from the QLoRA paper (including NF4 and DQ), shows virtually no reduction in performance with 4-bit quantization for both inferring and training large language models. NF4 and Double Quantization can be leveraged using the bitsandbytes library which is integrated inside the transformers library. Here is an example of how to easily load and quantize any Hugging Face model using the bitsandbytes library:","metadata":{"id":"qcS8j8iifUas"}},{"cell_type":"markdown","source":"**bnb_4bit_compute_dtype:**<br><br>\n\n- This parameter specifies the data type to be used for computation during training or inference with 4-bit quantized parameters. It is set based on the conditional logic in the previous code snippet, where torch_dtype is determined.\nIn the provided example, torch_dtype could be either torch.bfloat16 or torch.float16, depending on the CUDA device capability.","metadata":{"id":"EK6U4ku2dBN0"}},{"cell_type":"markdown","source":"The LoraConfig class is used to configure the LoRa (Layer-wise Relevance Analysis) technique for fine-tuning large language models. <br><br>\n\nThe parameters in the peft_config object are as follows:<br><br>\n\n\n**r:**\n\n- The r parameter specifies the rank of the LoRA projection matrix. This parameter controls the number of parameters used for fine-tuning. A higher rank leads to more parameters and potentially better performance, but it also increases the memory footprint of the model<br><br>\n\n\n**lora_alpha:**\n\n- The lora_alpha parameter controls the scale of the LoRA projection matrix.\nYou can use this parameter to adjust the learning rate for the fine-tuning process. For optimal results, set it to double the value of r.<br><br>\n\n\n**lora_dropout:**\n\n-  The lora_dropout parameter specifies the dropout rate for the LoRA projection matrix.\nThis parameter can help prevent overfitting and enhance the model’s generalization ability.<br><br>\n\n\n**bias:**\n\n- The bias parameter specifies whether to use a bias term in the LoRA projection matrix. Setting this to “none” implies that no bias term will be used.<br><br>\n\n\n**task_type:**\n\n- The task_type parameter specifies the type of task the model will be used for. In this case, the task type is set to “CAUSAL_LM”, indicating that the model will be used for causal language modeling.<br><br>\n\n**target_modules:**\n\n-  The list of modules in the model to apply the LoRa technique to. This parameter specifies the modules where the adapter matrices will be added.","metadata":{"id":"bGYb5Ov8gfPl"}},{"cell_type":"code","source":"# dataset_name = \"mlabonne/orpo-dpo-mix-40k\"\n# dataset = load_dataset(dataset_name, split=\"all\")\n# dataset = dataset.shuffle(seed=42).select(range(10))\n\n# def format_chat_template(row):\n#     row[\"chosen\"] = tokenizer.apply_chat_template(row[\"chosen\"], tokenize=False)\n#     row[\"rejected\"] = tokenizer.apply_chat_template(row[\"rejected\"], tokenize=False)\n#     return row\n\n# dataset = dataset.map(\n#     format_chat_template,\n#     num_proc= os.cpu_count(),\n# )\n# dataset = dataset.train_test_split(test_size=0.01)\n","metadata":{"id":"ajkwWc40hL0F","execution":{"iopub.status.busy":"2024-06-28T17:30:42.752421Z","iopub.execute_input":"2024-06-28T17:30:42.752702Z","iopub.status.idle":"2024-06-28T17:30:42.761702Z","shell.execute_reply.started":"2024-06-28T17:30:42.752679Z","shell.execute_reply":"2024-06-28T17:30:42.761057Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# orpo_args = ORPOConfig(\n#     learning_rate=8e-6,\n#     beta=0.1,\n#     lr_scheduler_type=\"linear\",\n#     max_length=1024,\n#     max_prompt_length=512,\n#     per_device_train_batch_size=2,\n#     per_device_eval_batch_size=2,\n#     gradient_accumulation_steps=4,\n#     optim=\"paged_adamw_8bit\",\n#     num_train_epochs=1,\n#     evaluation_strategy=\"steps\",\n#     eval_steps=0.2,\n#     logging_steps=1,\n#     warmup_steps=10,\n#     report_to=\"wandb\",\n#     output_dir=\"./results/\",\n# )\n\n# trainer = ORPOTrainer(\n#     model=model,\n#     args=orpo_args,\n#     train_dataset=dataset[\"train\"],\n#     eval_dataset=dataset[\"test\"],\n#     peft_config=peft_config,\n#     tokenizer=tokenizer,\n# )\n# trainer.train()\n# trainer.save_model(new_model)\n","metadata":{"id":"P63duVluhXGH","execution":{"iopub.status.busy":"2024-06-28T17:30:42.762651Z","iopub.execute_input":"2024-06-28T17:30:42.762908Z","iopub.status.idle":"2024-06-28T17:30:42.778381Z","shell.execute_reply.started":"2024-06-28T17:30:42.762886Z","shell.execute_reply":"2024-06-28T17:30:42.777687Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"border-radius: 20px; border: 2px solid #336699; padding: 20px; background-color: #e0f7fa; text-align: center; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.4), 0px 6px 20px rgba(0, 0, 0, 0.19); transform: perspective(1000px) rotateX(5deg) rotateY(-5deg); transition: transform 0.5s ease-in-out;\">\n    <h1 style=\"color: #003366; text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.4); font-weight: bold; margin-bottom: 10px; font-size: 32px;\">\n        Thank You!\n    </h1>\n    <p style=\"color: #003366; font-size: 18px; margin: 15px 0;\">\n        Thank you so much for joining me on this journey through the world of LLMS! Your support and enthusiasm have been incredibly motivating. 🌟\n    </p>\n    <blockquote style=\"border-left: 4px solid #336699; padding-left: 10px; color: #003366; font-size: 18px; margin: 20px 0; background-color: #f0f8ff; padding: 10px;\">\n        As I delve deeper into the realm of <strong>Generative AI</strong>, I am grateful for your continued encouragement and guidance. Together, we are pushing the boundaries of what's possible in data science and beyond. 🚀💡\n    </blockquote>\n    <blockquote style=\"border-left: 4px solid #336699; padding-left: 10px; color: #003366; font-size: 18px; margin: 20px 0; background-color: #f0f8ff; padding: 10px;\">\n        If you found this exploration helpful or insightful, please consider leaving an upvote. Your support fuels my passion to innovate and explore new frontiers in AI. Let's continue making a difference and shaping the future of <strong>Generative AI</strong> together! 🌌✨\n    </blockquote>","metadata":{}}]}