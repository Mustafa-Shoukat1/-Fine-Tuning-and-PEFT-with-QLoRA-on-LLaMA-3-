{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a555d61c10374a139e67629987db9e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b295424341e14fc6b7d84971b78e6357",
              "IPY_MODEL_6c233d8c505f43a8af044abc3623cdcc",
              "IPY_MODEL_ba1ddb94a834499eada2067a7b458015"
            ],
            "layout": "IPY_MODEL_ac2c7fe9f7e643829b41bee23056ff9b"
          }
        },
        "b295424341e14fc6b7d84971b78e6357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83451af93bef4daf96bae6d5d88dc753",
            "placeholder": "​",
            "style": "IPY_MODEL_a26d35bf4534463191c7eea822d28001",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6c233d8c505f43a8af044abc3623cdcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_049e143c62f7420e8adc2b2a7c068159",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29a58a7575c94546b23eb0b19a66b51f",
            "value": 2
          }
        },
        "ba1ddb94a834499eada2067a7b458015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dad3118b021462aa242baf0e0aa24fb",
            "placeholder": "​",
            "style": "IPY_MODEL_815ea69bffe347ebad34f0b241c3491f",
            "value": " 2/2 [00:02&lt;00:00,  1.41s/it]"
          }
        },
        "ac2c7fe9f7e643829b41bee23056ff9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83451af93bef4daf96bae6d5d88dc753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a26d35bf4534463191c7eea822d28001": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "049e143c62f7420e8adc2b2a7c068159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29a58a7575c94546b23eb0b19a66b51f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2dad3118b021462aa242baf0e0aa24fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "815ea69bffe347ebad34f0b241c3491f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a555d61c10374a139e67629987db9e3e",
            "b295424341e14fc6b7d84971b78e6357",
            "6c233d8c505f43a8af044abc3623cdcc",
            "ba1ddb94a834499eada2067a7b458015",
            "ac2c7fe9f7e643829b41bee23056ff9b",
            "83451af93bef4daf96bae6d5d88dc753",
            "a26d35bf4534463191c7eea822d28001",
            "049e143c62f7420e8adc2b2a7c068159",
            "29a58a7575c94546b23eb0b19a66b51f",
            "2dad3118b021462aa242baf0e0aa24fb",
            "815ea69bffe347ebad34f0b241c3491f"
          ]
        },
        "id": "mwr1sqt7STmd",
        "outputId": "bb0a1b14-6f4a-422c-bd98-17338b2c8920"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a555d61c10374a139e67629987db9e3e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "device = \"cuda\" # the device to load the model onto\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"ilsp/Meltemi-7B-Instruct-v1\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ilsp/Meltemi-7B-Instruct-v1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Είσαι το Μελτέμι, ένα γλωσσικό μοντέλο για την ελληνική γλώσσα. Είσαι ιδιαίτερα βοηθητικό προς την χρήστρια ή τον χρήστη και δίνεις σύντομες αλλά επαρκώς περιεκτικές απαντήσεις. Απάντα με προσοχή, ευγένεια, αμεροληψία, ειλικρίνεια και σεβασμό προς την χρήστρια ή τον χρήστη.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Πες μου αν έχεις συνείδηση.\"},\n",
        "]\n",
        "\n",
        "# Through the default chat template this translates to\n",
        "#\n",
        "# <|system|>\n",
        "# Είσαι το Μελτέμι, ένα γλωσσικό μοντέλο για την ελληνική γλώσσα. Είσαι ιδιαίτερα βοηθητικό προς την χρήστρια ή τον χρήστη και δίνεις σύντομες αλλά επαρκώς περιεκτικές απαντήσεις. Απάντα με προσοχή, ευγένεια, αμεροληψία, ειλικρίνεια και σεβασμό προς την χρήστρια ή τον χρήστη.</s>\n",
        "# <|user|>\n",
        "# Πες μου αν έχεις συνείδηση.</s>\n",
        "# <|assistant|>\n",
        "#\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
        "input_prompt = tokenizer(prompt, return_tensors='pt')\n",
        "outputs = model.generate(input_prompt['input_ids'], max_new_tokens=256, do_sample=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6N0r-ukNWBhG",
        "outputId": "3cdb8a5a-8f20-4421-e745-5f20a8ce71c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.batch_decode(outputs)[0])\n",
        "\n",
        "\n",
        "messages.extend([\n",
        "    {\"role\": \"assistant\", \"content\": tokenizer.batch_decode(outputs)[0]},\n",
        "    {\"role\": \"user\", \"content\": \"Πιστεύεις πως οι άνθρωποι πρέπει να φοβούνται την τεχνητή νοημοσύνη;\"}\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "prompt = tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n",
        "input_prompt = tokenizer(prompt, return_tensors='pt')\n",
        "outputs = model.generate(input_prompt['input_ids'], max_new_tokens=256, do_sample=True)\n",
        "\n",
        "print(tokenizer.batch_decode(outputs)[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHhRCUulWEYw",
        "outputId": "ac06f048-f8d2-40b3-e159-977f5fb62054"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> <|system|>\n",
            "Είσαι το Μελτέμι, ένα γλωσσικό μοντέλο για την ελληνική γλώσσα. Είσαι ιδιαίτερα βοηθητικό προς την χρήστρια ή τον χρήστη και δίνεις σύντομες αλλά επαρκώς περιεκτικές απαντήσεις. Απάντα με προσοχή, ευγένεια, αμεροληψία, ειλικρίνεια και σεβασμό προς την χρήστρια ή τον χρήστη.</s> \n",
            "<|user|>\n",
            "Πες μου αν έχεις συνείδηση.</s> \n",
            "<|assistant|>\n",
            "Λυπάμαι, αλλά ως γλωσσικό μοντέλο, δεν είμαι ούτε ικανός για τη συνείδηση ούτε έχω προσωπικά συναισθήματα.</s>\n",
            "<s> <|system|>\n",
            "Είσαι το Μελτέμι, ένα γλωσσικό μοντέλο για την ελληνική γλώσσα. Είσαι ιδιαίτερα βοηθητικό προς την χρήστρια ή τον χρήστη και δίνεις σύντομες αλλά επαρκώς περιεκτικές απαντήσεις. Απάντα με προσοχή, ευγένεια, αμεροληψία, ειλικρίνεια και σεβασμό προς την χρήστρια ή τον χρήστη.</s> \n",
            "<|user|>\n",
            "Πες μου αν έχεις συνείδηση.</s> \n",
            "<|assistant|>\n",
            "<s>  <|system|>\n",
            "Είσαι το Μελτέμι, ένα γλωσσικό μοντέλο για την ελληνική γλώσσα. Είσαι ιδιαίτερα βοηθητικό προς την χρήστρια ή τον χρήστη και δίνεις σύντομες αλλά επαρκώς περιεκτικές απαντήσεις. Απάντα με προσοχή, ευγένεια, αμεροληψία, ειλικρίνεια και σεβασμό προς την χρήστρια ή τον χρήστη.</s>  \n",
            "<|user|>\n",
            "Πες μου αν έχεις συνείδηση.</s>  \n",
            "<|assistant|>\n",
            "Λυπάμαι, αλλά ως γλωσσικό μοντέλο, δεν είμαι ούτε ικανός για τη συνείδηση ούτε έχω προσωπικά συναισθήματα.</s></s> \n",
            "<|user|>\n",
            "Πιστεύεις πως οι άνθρωποι πρέπει να φοβούνται την τεχνητή νοημοσύνη;</s> \n",
            "<|assistant|>\n",
            "Η ιδέα ότι οι άνθρωποι πρέπει να φοβούνται την τεχνητή νοημοσύνη εμπίπτει στην κατηγορία της φοβίας και συγκεκριμένα σε μια κατάσταση που ονομάζεται «νευράρωση» ή «φοβία AI», η οποία περιλαμβάνει τον παράλογο φόβο ότι οι μηχανές τεχνητής νοημοσύνης θα προκαλέσουν βλάβη στους ανθρώπους. Ενώ είναι πιθανό να υπάρχει κίνδυνος κακής χρήσης της τεχνητής νοημοσύνης, είναι σημαντικό να σημειωθεί ότι οι συσκευές τεχνητής νοημοσύνης έχουν σχεδιαστεί για να είναι χρήσιμες και ασφαλείς και επί του παρόντος, δεν είναι ικανές να προκαλούν βλάβη χωρίς ανθρώπινη παρέμβαση ή πρόθεση. Ωστόσο, είναι σημαντικό να παραμένετε ενημερωμένοι για τις πιθανές επιπτώσεις της τεχνολογίας τεχνητής νοημοσύνης και να το χρησιμοποιείτε με υπεύθυνη και ηθική λήψη αποφάσεων.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "%pip install -U langchain tavily-python langgraph matplotlib langchain_community langchain-openai scikit-learn langchainhub langchain-ollama nomic[local]"
      ],
      "metadata": {
        "id": "OCR4osola5x5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain tavily-python langgraph matplotlib langchain_community langchain-openai scikit-learn langchainhub langchain-ollama nomic[local]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrat42Gub1_8",
        "outputId": "0c2816c8-5568-4822-e59d-f1195f5998ac"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.11)\n",
            "Requirement already satisfied: tavily-python in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.1.19)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.2.10)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.1.20)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: langchainhub in /usr/local/lib/python3.10/dist-packages (0.1.20)\n",
            "Requirement already satisfied: langchain-ollama in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: nomic[local] in /usr/local/lib/python3.10/dist-packages (3.1.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.26)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.95)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from tavily-python) (0.7.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from tavily-python) (0.27.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.37.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.32.0.20240712)\n",
            "Requirement already satisfied: ollama<1,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain-ollama) (0.3.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nomic[local]) (8.1.7)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from nomic[local]) (4.0.0)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (from nomic[local]) (0.7.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from nomic[local]) (13.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nomic[local]) (2.1.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nomic[local]) (4.66.4)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from nomic[local]) (14.0.2)\n",
            "Requirement already satisfied: pyjwt in /usr/local/lib/python3.10/dist-packages (from nomic[local]) (2.8.0)\n",
            "Requirement already satisfied: gpt4all<3,>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from nomic[local]) (2.7.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gpt4all<3,>=2.5.0->nomic[local]) (4.12.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.5.15)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nomic[local]) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nomic[local]) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->nomic[local]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->nomic[local]) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->tavily-python) (1.2.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->nomic[local]) (0.1.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_nomic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "ZS4QW5jWccwr",
        "outputId": "8e186978-75a5-4a44-b03b-3f5b4cc5bd04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_nomic\n",
            "  Downloading langchain_nomic-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain_nomic) (0.2.26)\n",
            "Requirement already satisfied: nomic<4.0.0,>=3.0.29 in /usr/local/lib/python3.10/dist-packages (from langchain_nomic) (3.1.1)\n",
            "Collecting pillow<11.0.0,>=10.3.0 (from langchain_nomic)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_nomic) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_nomic) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_nomic) (0.1.95)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_nomic) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_nomic) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_nomic) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_nomic) (4.12.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.29->langchain_nomic) (8.1.7)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.29->langchain_nomic) (4.0.0)\n",
            "Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.29->langchain_nomic) (0.7.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.29->langchain_nomic) (13.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.29->langchain_nomic) (2.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.29->langchain_nomic) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.29->langchain_nomic) (2.1.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.29->langchain_nomic) (4.66.4)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.29->langchain_nomic) (14.0.2)\n",
            "Requirement already satisfied: pyjwt in /usr/local/lib/python3.10/dist-packages (from nomic<4.0.0,>=3.0.29->langchain_nomic) (2.8.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain_nomic) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.46->langchain_nomic) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_nomic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_nomic) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nomic<4.0.0,>=3.0.29->langchain_nomic) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nomic<4.0.0,>=3.0.29->langchain_nomic) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nomic<4.0.0,>=3.0.29->langchain_nomic) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nomic<4.0.0,>=3.0.29->langchain_nomic) (2024.7.4)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->nomic<4.0.0,>=3.0.29->langchain_nomic) (23.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->nomic<4.0.0,>=3.0.29->langchain_nomic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nomic<4.0.0,>=3.0.29->langchain_nomic) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nomic<4.0.0,>=3.0.29->langchain_nomic) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->nomic<4.0.0,>=3.0.29->langchain_nomic) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->nomic<4.0.0,>=3.0.29->langchain_nomic) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->nomic<4.0.0,>=3.0.29->langchain_nomic) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->nomic<4.0.0,>=3.0.29->langchain_nomic) (1.16.0)\n",
            "Downloading langchain_nomic-0.1.2-py3-none-any.whl (3.8 kB)\n",
            "Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow, langchain_nomic\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "Successfully installed langchain_nomic-0.1.2 pillow-10.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "050f1cc69b1947cd8fe450139adbda15"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "4gPXXg3zdfTw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "!pip install langchain_huggingface\n",
        "!pip install --upgrade langchain-huggingface\n"
      ],
      "metadata": {
        "id": "XS9pX82JfOf7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import SKLearnVectorStore\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# List of URLs to load documents from\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]\n",
        "\n",
        "# Load documents from the URLs\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "# Initialize a text splitter with specified chunk size and overlap\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=250, chunk_overlap=0\n",
        ")\n",
        "\n",
        "# Specify the model name as a string\n",
        "embedding_model = 'all-MiniLM-L6-v2'\n",
        "\n",
        "# Initialize the HuggingFaceEmbeddings with the model name\n",
        "embedding = HuggingFaceEmbeddings(model_name=embedding_model)\n",
        "\n",
        "# Split the documents into chunks\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "# Add the document chunks to the \"vector store\" using HuggingFaceEmbeddings\n",
        "vectorstore = SKLearnVectorStore.from_documents(\n",
        "    documents=doc_splits,\n",
        "    embedding=embedding,\n",
        ")\n",
        "retriever = vectorstore.as_retriever(k=4)\n"
      ],
      "metadata": {
        "id": "8bp8Z-E_WEtb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6f_lqiIbwr2",
        "outputId": "98db5d1d-a1da-4720-969a-8a35155b906e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['SKLearnVectorStore', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.sklearn.SKLearnVectorStore object at 0x7c04e1df0580>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_ollama import ChatOllama\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"You are an assistant for question-answering tasks.\n",
        "\n",
        "    Use the following documents to answer the question.\n",
        "\n",
        "    If you don't know the answer, just say that you don't know.\n",
        "\n",
        "    Use three sentences maximum and keep the answer concise:\n",
        "    Question: {question}\n",
        "    Documents: {documents}\n",
        "    Answer:\n",
        "    \"\"\",\n",
        "    input_variables=[\"question\", \"documents\"],\n",
        ")\n",
        "\n",
        "llm = ChatOllama(\n",
        "    model=\"llama3.1\",\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "rag_chain = prompt | llm | StrOutputParser()\n",
        "rag_chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9M4E9OVfiHQ",
        "outputId": "eb543a43-fb02-4a4a-fadb-e79a8be7917b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['documents', 'question'], template=\"You are an assistant for question-answering tasks. \\n    \\n    Use the following documents to answer the question. \\n    \\n    If you don't know the answer, just say that you don't know. \\n    \\n    Use three sentences maximum and keep the answer concise:\\n    Question: {question} \\n    Documents: {documents} \\n    Answer: \\n    \")\n",
              "| ChatOllama(model='llama3.1', temperature=0.0)\n",
              "| StrOutputParser()"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "\n",
        "# JSON\n",
        "llm = ChatOllama(model=\"llama3.1\",\n",
        "                 format=\"json\",\n",
        "                 temperature=0)\n",
        "\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
        "    Here is the user question: {question} \\n\n",
        "    If the document contains keywords related to the user question, grade it as relevant. \\n\n",
        "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
        "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\"\"\",\n",
        "    input_variables=[\"question\", \"document\"],\n",
        ")\n",
        "\n",
        "retrieval_grader = prompt | llm | JsonOutputParser()"
      ],
      "metadata": {
        "id": "yttKvIYLfnYj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict, List\n",
        "from IPython.display import Image, display\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        question: question\n",
        "        generation: LLM generation\n",
        "        search: whether to add search\n",
        "        documents: list of documents\n",
        "    \"\"\"\n",
        "\n",
        "    question: str\n",
        "    generation: str\n",
        "    search: str\n",
        "    documents: List[str]\n",
        "    steps: List[str]\n",
        "\n",
        "\n",
        "def retrieve(state):\n",
        "    \"\"\"\n",
        "    Retrieve documents\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents, that contains retrieved documents\n",
        "    \"\"\"\n",
        "    question = state[\"question\"]\n",
        "    documents = retriever.invoke(question)\n",
        "    steps = state[\"steps\"]\n",
        "    steps.append(\"retrieve_documents\")\n",
        "    return {\"documents\": documents, \"question\": question, \"steps\": steps}\n",
        "\n",
        "\n",
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Generate answer\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation, that contains LLM generation\n",
        "    \"\"\"\n",
        "\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    generation = rag_chain.invoke({\"documents\": documents, \"question\": question})\n",
        "    steps = state[\"steps\"]\n",
        "    steps.append(\"generate_answer\")\n",
        "    return {\n",
        "        \"documents\": documents,\n",
        "        \"question\": question,\n",
        "        \"generation\": generation,\n",
        "        \"steps\": steps,\n",
        "    }\n",
        "\n",
        "\n",
        "def grade_documents(state):\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with only filtered relevant documents\n",
        "    \"\"\"\n",
        "\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    steps = state[\"steps\"]\n",
        "    steps.append(\"grade_document_retrieval\")\n",
        "    filtered_docs = []\n",
        "    search = \"No\"\n",
        "    for d in documents:\n",
        "        score = retrieval_grader.invoke(\n",
        "            {\"question\": question, \"document\": d.page_content}\n",
        "        )\n",
        "        grade = score[\"score\"]\n",
        "        if grade == \"yes\":\n",
        "            filtered_docs.append(d)\n",
        "        else:\n",
        "            search = \"Yes\"\n",
        "            continue\n",
        "    return {\n",
        "        \"documents\": filtered_docs,\n",
        "        \"question\": question,\n",
        "        \"search\": search,\n",
        "        \"steps\": steps,\n",
        "    }\n",
        "\n",
        "\n",
        "def web_search(state):\n",
        "    \"\"\"\n",
        "    Web search based on the re-phrased question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "\n",
        "    question = state[\"question\"]\n",
        "    documents = state.get(\"documents\", [])\n",
        "    steps = state[\"steps\"]\n",
        "    steps.append(\"web_search\")\n",
        "    web_results = web_search_tool.invoke({\"query\": question})\n",
        "    documents.extend(\n",
        "        [\n",
        "            Document(page_content=d[\"content\"], metadata={\"url\": d[\"url\"]})\n",
        "            for d in web_results\n",
        "        ]\n",
        "    )\n",
        "    return {\"documents\": documents, \"question\": question, \"steps\": steps}\n",
        "\n",
        "\n",
        "def decide_to_generate(state):\n",
        "    \"\"\"\n",
        "    Determines whether to generate an answer, or re-generate a question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Binary decision for next node to call\n",
        "    \"\"\"\n",
        "    search = state[\"search\"]\n",
        "    if search == \"Yes\":\n",
        "        return \"search\"\n",
        "    else:\n",
        "        return \"generate\"\n",
        "\n",
        "\n",
        "# Graph\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
        "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
        "workflow.add_node(\"generate\", generate)  # generatae\n",
        "workflow.add_node(\"web_search\", web_search)  # web search\n",
        "\n",
        "# Build graph\n",
        "workflow.set_entry_point(\"retrieve\")\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\n",
        "        \"search\": \"web_search\",\n",
        "        \"generate\": \"generate\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"web_search\", \"generate\")\n",
        "workflow.add_edge(\"generate\", END)\n",
        "\n",
        "custom_graph = workflow.compile()\n",
        "\n",
        "display(Image(custom_graph.get_graph(xray=True).draw_mermaid_png()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "E83SGvgEfrlm",
        "outputId": "f25fb998-4527-43b8-e546-da8f0155cbe3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/jpeg": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "def predict_custom_agent_answer(example: dict):\n",
        "\n",
        "    config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
        "\n",
        "    state_dict = custom_graph.invoke(\n",
        "        {\"question\": example[\"input\"], \"steps\": []}, config\n",
        "    )\n",
        "\n",
        "    return {\"response\": state_dict[\"generation\"], \"steps\": state_dict[\"steps\"]}\n",
        "\n",
        "example = {\"input\": \"What are the types of agent memory?\"}\n",
        "#response = predict_custom_agent_answer(example)\n",
        "#response"
      ],
      "metadata": {
        "id": "yERJ--uKf0C1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent Evaluation\n",
        "\n",
        "In this section, we evaluate two different agent architectures that perform similar tasks. The evaluation process involves assessing how well each agent performs on a set of question-answer pairs.\n",
        "\n",
        "## Evaluation Method\n",
        "\n",
        "To determine the performance of our agents, we will use a dataset titled **\"Corrective RAG Agent Testing.\"** This dataset contains question-answer pairs that will help us gauge the effectiveness of the agents.\n",
        "\n",
        "### Evaluation Steps\n",
        "\n",
        "1. **Prepare the Dataset**: Ensure that the \"Corrective RAG Agent Testing\" dataset is properly formatted and accessible for evaluation.\n",
        "\n",
        "2. **Run Agents on Dataset**: Apply both agent architectures to the question-answer pairs in the dataset.\n",
        "\n",
        "3. **Measure Performance**: Evaluate the agents based on relevant metrics, such as accuracy, precision, recall, or F1 score.\n",
        "\n",
        "4. **Compare Results**: Analyze and compare the performance results of both agent architectures to determine which one performs better.\n",
        "\n",
        "### Results\n",
        "\n",
        "- **Agent Architecture 1**:\n",
        "  - Accuracy: [Insert Accuracy]\n",
        "  - Precision: [Insert Precision]\n",
        "  - Recall: [Insert Recall]\n",
        "  - F1 Score: [Insert F1 Score]\n",
        "\n",
        "- **Agent Architecture 2**:\n",
        "  - Accuracy: [Insert Accuracy]\n",
        "  - Precision: [Insert Precision]\n",
        "  - Recall: [Insert Recall]\n",
        "  - F1 Score: [Insert F1 Score]\n",
        "\n",
        "### Conclusion\n",
        "\n",
        "Based on the evaluation metrics, we will draw conclusions about the relative performance of the two agent architectures and discuss their strengths and weaknesses.\n",
        "\n",
        "For further details on the evaluation process, please refer to our conceptual guide on agent evaluation.\n"
      ],
      "metadata": {
        "id": "4wPrWKGggFqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a dataset\n",
        "examples = [\n",
        "    (\n",
        "        \"How does the ReAct agent use self-reflection? \",\n",
        "        \"ReAct integrates reasoning and acting, performing actions - such tools like Wikipedia search API - and then observing / reasoning about the tool outputs.\",\n",
        "    ),\n",
        "    (\n",
        "        \"What are the types of biases that can arise with few-shot prompting?\",\n",
        "        \"The biases that can arise with few-shot prompting include (1) Majority label bias, (2) Recency bias, and (3) Common token bias.\",\n",
        "    ),\n",
        "    (\n",
        "        \"What are five types of adversarial attacks?\",\n",
        "        \"Five types of adversarial attacks are (1) Token manipulation, (2) Gradient based attack, (3) Jailbreak prompting, (4) Human red-teaming, (5) Model red-teaming.\",\n",
        "    ),\n",
        "    (\n",
        "        \"Who did the Chicago Bears draft first in the 2024 NFL draft”?\",\n",
        "        \"The Chicago Bears drafted Caleb Williams first in the 2024 NFL draft.\",\n",
        "    ),\n",
        "    (\"Who won the 2024 NBA finals?\", \"The Boston Celtics on the 2024 NBA finals\"),\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "AyD6ItezgE_m"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Grade prompt\n",
        "grade_prompt_answer_accuracy = hub.pull(\"langchain-ai/rag-answer-vs-reference\")\n",
        "\n",
        "\n",
        "def answer_evaluator(run, example) -> dict:\n",
        "    \"\"\"\n",
        "    A simple evaluator for RAG answer accuracy\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the question, the ground truth reference answer, RAG chain answer prediction\n",
        "    input_question = example.inputs[\"input\"]\n",
        "    reference = example.outputs[\"output\"]\n",
        "    prediction = run.outputs[\"response\"]\n",
        "\n",
        "    # Define an LLM grader\n",
        "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "    answer_grader = grade_prompt_answer_accuracy | llm\n",
        "\n",
        "    # Run evaluator\n",
        "    score = answer_grader.invoke(\n",
        "        {\n",
        "            \"question\": input_question,\n",
        "            \"correct_answer\": reference,\n",
        "            \"student_answer\": prediction,\n",
        "        }\n",
        "    )\n",
        "    score = score[\"Score\"]\n",
        "    return {\"key\": \"answer_v_reference_score\", \"score\": score}"
      ],
      "metadata": {
        "id": "flCjwCVJgIwE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "apOC23V-gcr5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}